<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="0. 前言因为在person-reid论文HHL中涉及到了starGAN，所以做一个StarGAN的阅读记录，并比较与CycleGAN的区别。 StarGAN Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation Yunjey Choi, Minje Choi, Munyoung Ki">
<meta property="og:type" content="article">
<meta property="og:title" content="starGAN">
<meta property="og:url" content="http://example.com/2018/12/19/starGAN/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="0. 前言因为在person-reid论文HHL中涉及到了starGAN，所以做一个StarGAN的阅读记录，并比较与CycleGAN的区别。 StarGAN Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation Yunjey Choi, Minje Choi, Munyoung Ki">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN1.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN1.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN2.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN2.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN3.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN3.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN5.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN5.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN6.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN6.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN7.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN7.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN4.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN4.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN8.png">
<meta property="og:image" content="http://example.com/2018/12/19/starGAN/starGAN8.png">
<meta property="article:published_time" content="2018-12-19T01:44:59.000Z">
<meta property="article:modified_time" content="2018-12-23T15:11:34.619Z">
<meta property="article:author" content="TianJiajie">
<meta property="article:tag" content="GAN">
<meta property="article:tag" content="starGAN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2018/12/19/starGAN/starGAN1.png">

<link rel="canonical" href="http://example.com/2018/12/19/starGAN/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>starGAN | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/12/19/starGAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="TianJiajie">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          starGAN
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-12-19 09:44:59" itemprop="dateCreated datePublished" datetime="2018-12-19T09:44:59+08:00">2018-12-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2018-12-23 23:11:34" itemprop="dateModified" datetime="2018-12-23T23:11:34+08:00">2018-12-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/paper/" itemprop="url" rel="index"><span itemprop="name">paper</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h1><p>因为在person-reid论文<a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Zhun_Zhong_Generalizing_A_Person_ECCV_2018_paper.pdf">HHL</a>中涉及到了starGAN，所以做一个StarGAN的阅读记录，并比较与CycleGAN的区别。</p>
<p><a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_StarGAN_Unified_Generative_CVPR_2018_paper.pdf">StarGAN Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation</a></p>
<p>Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo</p>
<span id="more"></span>
<p>code-pytorch-official: <a target="_blank" rel="noopener" href="https://github.com/yunjey/stargan">https://github.com/yunjey/stargan</a><br>code-tensorflow: &lt;<a target="_blank" rel="noopener" href="https://github.com/taki0112/StarGAN-Tensorflow">https://github.com/taki0112/StarGAN-Tensorflow</a> &gt;</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>解决多域之间图像转换一对多的问题，本文主要针对人脸进行改变。</p>
<p><strong>关键词</strong>：multi-domain image-image translation</p>
<p><strong>效果</strong>：转换效果如图所示</p>
<p><img src="/2018/12/19/starGAN/starGAN1.png" alt="转换效果"><br><img src="/2018/12/19/starGAN/starGAN1.png" class title="转换效果"></p>
<p><strong>网络模型</strong>：CycleGAN和StarGAN模型对比</p>
<p>starGAN有一个生成器G，两个判别器。</p>
<p><img src="/2018/12/19/starGAN/starGAN2.png" alt="CycleGAN和StarGAN模型对比"><br><img src="/2018/12/19/starGAN/starGAN2.png" class title="CycleGAN和StarGAN模型对比"></p>
<p><strong>备注</strong>：</p>
<p>multi-domain：单数据集的不同属性作为了一个domain</p>
<p>multi-datasets：不同数据集的不同属性</p>
<p>starGAN 分为multi-domain和multi-dataset两种。</p>
<h1 id="2-Star-Generative-Adversarial-Networks"><a href="#2-Star-Generative-Adversarial-Networks" class="headerlink" title="2. Star Generative Adversarial Networks"></a>2. Star Generative Adversarial Networks</h1><h2 id="2-1-Multi-Domain-Image-to-Image-Translation"><a href="#2-1-Multi-Domain-Image-to-Image-Translation" class="headerlink" title="2.1  Multi-Domain Image-to-Image Translation"></a>2.1  Multi-Domain Image-to-Image Translation</h2><p><strong>starGAN</strong>: starGAN的训练模型</p>
<p><img src="/2018/12/19/starGAN/starGAN3.png" alt="starGAN in mutli domain"><br><img src="/2018/12/19/starGAN/starGAN3.png" class title="starGAN in mutli domain"></p>
<blockquote>
<p>To achieve this, we train G to translate an input image x into an output image y conditioned on the target domain label c, <strong>G(x; c) -&gt; y</strong>. We randomly generate the target domain label c so that G learns to flexibly translate the input image. We also introduce an auxiliary classifier [22] that allows a single discriminator to control multiple domains. That is, our discriminator produces probability distributions over both sources and domain labels, <strong>D:x-&gt;{$D<em>{src}$(x); $D</em>{cls}$(x)}</strong></p>
</blockquote>
<p><strong>符号说明</strong>：符号表</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">符号</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">x</td>
<td style="text-align:center">input image</td>
</tr>
<tr>
<td style="text-align:center">c</td>
<td style="text-align:center">target domain label</td>
</tr>
<tr>
<td style="text-align:center">c’</td>
<td style="text-align:center">source domain label</td>
</tr>
<tr>
<td style="text-align:center">y</td>
<td style="text-align:center">generate image</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Loss</strong>: training loss</p>
<p><strong>Adversarial Loss</strong>:(CycleGAN也有)对抗损失</p>
<script type="math/tex; mode=display">L_{adv}=E_x[log D_{src}(x)]+E_{x,c}[log (1-D_{src}(G(x,c)))] \tag{1}</script><p><strong>Domain Classification Loss</strong>:(特有)分类损失</p>
<blockquote>
<p>That is, we decompose the objective into two terms: a domain classification loss of real images used to optimize D, and a domain classification loss of fake images used to optimize G.</p>
</blockquote>
<p><em>优化 D</em>:</p>
<script type="math/tex; mode=display">L_{cls}^r=E_{x,c'}[-log D_{cls}(c'|x)] \tag{2}</script><blockquote>
<p>By minimizing this objective, D learns to classify a real image x to its corresponding original domain c’.</p>
</blockquote>
<p><em>优化 G</em>:</p>
<script type="math/tex; mode=display">L_{cls}^f=E_{x,c}[-log D_{cls}(c|G(x,c))] \tag{3}</script><blockquote>
<p>G tries to minimize this objective to generate images that can be classified as the target domain c.</p>
</blockquote>
<p><strong>Reconstruction Loss</strong>: (共有)重构损失</p>
<script type="math/tex; mode=display">L_{rec}=E_{x,c,c'}[\parallel x-G(G(x,c),c') \parallel _1]  \tag{4}</script><p><strong>Full Objective</strong>: 共有</p>
<script type="math/tex; mode=display">L_D=-L_{adv}+\lambda_{cls} L_{cls}^r</script><script type="math/tex; mode=display">L_G=L_{adv}+\lambda_{cls} L_{cls}^f+\lambda_{rec}L_{rec} \tag{5}</script><script type="math/tex; mode=display">\lambda_{cls}=1, \lambda_{rec}=10</script><h2 id="2-2-Training-with-Multiple-Datasets"><a href="#2-2-Training-with-Multiple-Datasets" class="headerlink" title="2.2. Training with Multiple Datasets"></a>2.2. Training with Multiple Datasets</h2><p><img src="/2018/12/19/starGAN/starGAN5.png" alt="starGAN in multi datasets"><br><img src="/2018/12/19/starGAN/starGAN5.png" class title="starGAN in multi datasets"></p>
<p>StarGAN也适用于多数据集间的转换，上述过程中的重构损失要求数据集之间的标签一致(？？？)。针对这个问题，作者引入Mask Vector.</p>
<p><strong>Mask Vector</strong>: 修改真值。</p>
<script type="math/tex; mode=display">\tilde{c} = [c_1, ..., c_n, m]</script><blockquote>
<p>$c_i$ represents a vector for the labels of the i-th dataset. The vector of the known label $c_i$ can be represented as either a binary vector for binary attributes or a one-hot vector for categorical attributes. For the remaining n−1 unknown labels we simply assign zero values.</p>
</blockquote>
<p>这样的话，所有的c都需要变成$\tilde{c}$</p>
<h1 id="3-Implementation"><a href="#3-Implementation" class="headerlink" title="3. Implementation"></a>3. Implementation</h1><p><strong>Improved GAN training</strong>: 为了稳定训练过程，替代方程1.</p>
<script type="math/tex; mode=display">L_{adv}=E_x[log D_{src}(x)]-E_{x,c}[log (D_{src}(G(x,c)))]-\lambda_{gp}E_{\hat{x}}[(\parallel \nabla_{\hat{x}}  D_{src}(\hat{x}) \parallel_2-1)^2] \tag{6}</script><script type="math/tex; mode=display">\lambda_{gp}=10</script><p><strong>Network Architecture</strong>: 类似CycleGAN。</p>
<p>G: Leaky ReLU: 0.01</p>
<p><img src="/2018/12/19/starGAN/starGAN6.png" alt="G"><br><img src="/2018/12/19/starGAN/starGAN6.png" class title="G"></p>
<p>D: PatchGAN</p>
<p>现在网络架构可以看到的是作者使用的不是70x70的patchGAN，通过patchGAN的论文，也没有看到这种结构。</p>
<p><img src="/2018/12/19/starGAN/starGAN7.png" alt="D"><br><img src="/2018/12/19/starGAN/starGAN7.png" class></p>
<h1 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4. Experiments"></a>4. Experiments</h1><h2 id="4-1-Baseline-Models"><a href="#4-1-Baseline-Models" class="headerlink" title="4.1 Baseline Models"></a>4.1 Baseline Models</h2><p><img src="/2018/12/19/starGAN/starGAN4.png" alt="baseline models"><br><img src="/2018/12/19/starGAN/starGAN4.png" class title="baseline models"></p>
<p>通过结果可以看出，在Gender这个属性，ICGAN的转换效果要更好一些，但是损失了ID信息。</p>
<h2 id="4-2-Training"><a href="#4-2-Training" class="headerlink" title="4.2 Training"></a>4.2 Training</h2><ul>
<li>Adam: $\beta_1=0.5, \beta_2=0.999$</li>
<li>Updates: one generator update after five discriminator updates</li>
<li>lr: For CelebA, 0.0001 for the first 100000 epochs, and linearly decay the lr to 0 over the next 100000 epochs. For the RaFD, 0.0001 for the first 100000 epochs, and linearly decay the lr to 0 over the next 100000 epochs.作者在论文写的是10和100，但是代码显示的是100000</li>
<li>batch: 16</li>
<li>input: For CelebA, crop: 178, resize: 128; For RaFD, </li>
</ul>
<h2 id="4-3-Results"><a href="#4-3-Results" class="headerlink" title="4.3 Results"></a>4.3 Results</h2><p>作者通过人脸的转换实验，不仅说明了StarGAN在单数据集的不同domian中效果好，而且在多数据集的不同domian中效果也好。</p>
<h1 id="5-代码"><a href="#5-代码" class="headerlink" title="5. 代码"></a>5. 代码</h1><p>在这里分析pytorch的代码，并对其中关键的代码进行解读。</p>
<p>如果不说明，则假设讨论单数据集的多域。</p>
<h2 id="5-1-Model-G-and-D"><a href="#5-1-Model-G-and-D" class="headerlink" title="5.1 Model: G and D"></a>5.1 Model: G and D</h2><p><strong>Generator</strong>:<br>生成器Generator，结构与前面提到的网络架构一致，这里需要注意两点：</p>
<ul>
<li>当训练集是单数据集的多domain时，label需要扩充成图片大小，一起输入网络(这里有个疑问：网络真得能知道后面的通道是label吗)</li>
<li>当训练集是多数据集的多domain时，label的维度是c+c2+2，因为有mask，同样需要广播成图片大小，一起输入网络</li>
</ul>
<p><strong>Discriminator</strong>:<br>判别器Discriminator，有个疑问是关于是感受野和计算损失的。</p>
<p><img src="/2018/12/19/starGAN/starGAN8.png" alt="感受野"><br><img src="/2018/12/19/starGAN/starGAN8.png" class title="感受野"></p>
<p>下面会提及到计算损失的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResidualBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Residual Block with instance normalization.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim_in, dim_out</span>):</span><br><span class="line">        <span class="built_in">super</span>(ResidualBlock, self).__init__()</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            nn.Conv2d(dim_in, dim_out, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.InstanceNorm2d(dim_out, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(dim_out, dim_out, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.InstanceNorm2d(dim_out, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x + self.main(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Generator network.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, conv_dim=<span class="number">64</span>, c_dim=<span class="number">5</span>, repeat_num=<span class="number">6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(nn.Conv2d(<span class="number">3</span>+c_dim, conv_dim, kernel_size=<span class="number">7</span>, stride=<span class="number">1</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>))</span><br><span class="line">        layers.append(nn.InstanceNorm2d(conv_dim, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>))</span><br><span class="line">        layers.append(nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Down-sampling layers.</span></span><br><span class="line">        curr_dim = conv_dim</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            layers.append(nn.Conv2d(curr_dim, curr_dim*<span class="number">2</span>, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>))</span><br><span class="line">            layers.append(nn.InstanceNorm2d(curr_dim*<span class="number">2</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>))</span><br><span class="line">            layers.append(nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line">            curr_dim = curr_dim * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Bottleneck layers.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(repeat_num):</span><br><span class="line">            layers.append(ResidualBlock(dim_in=curr_dim, dim_out=curr_dim))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Up-sampling layers.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            layers.append(nn.ConvTranspose2d(curr_dim, curr_dim//<span class="number">2</span>, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>))</span><br><span class="line">            layers.append(nn.InstanceNorm2d(curr_dim//<span class="number">2</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>))</span><br><span class="line">            layers.append(nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line">            curr_dim = curr_dim // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        layers.append(nn.Conv2d(curr_dim, <span class="number">3</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">1</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>))</span><br><span class="line">        layers.append(nn.Tanh())</span><br><span class="line">        self.main = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, c</span>):</span><br><span class="line">        <span class="comment"># Replicate spatially and concatenate domain information.</span></span><br><span class="line">        <span class="comment"># c: N*c_dim</span></span><br><span class="line">        <span class="comment"># 生成器直接将目标域c在通道维度进行拼接</span></span><br><span class="line">        c = c.view(c.size(<span class="number">0</span>), c.size(<span class="number">1</span>), <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        c = c.repeat(<span class="number">1</span>, <span class="number">1</span>, x.size(<span class="number">2</span>), x.size(<span class="number">3</span>))</span><br><span class="line">        x = torch.cat([x, c], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.main(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Discriminator network with PatchGAN.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_size=<span class="number">128</span>, conv_dim=<span class="number">64</span>, c_dim=<span class="number">5</span>, repeat_num=<span class="number">6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(nn.Conv2d(<span class="number">3</span>, conv_dim, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line">        layers.append(nn.LeakyReLU(<span class="number">0.01</span>))</span><br><span class="line"></span><br><span class="line">        curr_dim = conv_dim</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, repeat_num):</span><br><span class="line">            layers.append(nn.Conv2d(curr_dim, curr_dim*<span class="number">2</span>, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line">            layers.append(nn.LeakyReLU(<span class="number">0.01</span>))</span><br><span class="line">            curr_dim = curr_dim * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        kernel_size = <span class="built_in">int</span>(image_size / np.power(<span class="number">2</span>, repeat_num))</span><br><span class="line">        self.main = nn.Sequential(*layers)</span><br><span class="line">        self.conv1 = nn.Conv2d(curr_dim, <span class="number">1</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(curr_dim, c_dim, kernel_size=kernel_size, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        h = self.main(x)</span><br><span class="line">        <span class="comment"># True or False</span></span><br><span class="line">        out_src = self.conv1(h)</span><br><span class="line">        <span class="comment"># classes onehot</span></span><br><span class="line">        out_cls = self.conv2(h)</span><br><span class="line">        <span class="keyword">return</span> out_src, out_cls.view(out_cls.size(<span class="number">0</span>), out_cls.size(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h2 id="5-2-input"><a href="#5-2-input" class="headerlink" title="5.2 input"></a>5.2 input</h2><p>对于任一张图片，其target label是随机取其他图片的label，而没有刻意去指定</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># label_org和label_trg可以认为是单个图片的真实label，形式可以是[0,1,1,0]或者4，根据不同的数据集形式进行处理，前者是多分类label，后者是单分类label，用于计算损失</span></span><br><span class="line"><span class="comment"># c_org，c_trg是与图片一起输入网络的&#123;0,1&#125;向量，形式是[0,1,1,0]或者是[0,0,0,1]的形式，用于网络的输入</span></span><br><span class="line">x_real, label_org = <span class="built_in">next</span>(data_iter)</span><br><span class="line">rand_idx = torch.randperm(label_org.size(<span class="number">0</span>))</span><br><span class="line">label_trg = label_org[rand_idx]</span><br><span class="line"><span class="keyword">if</span> self.dataset == <span class="string">&#x27;CelebA&#x27;</span>:</span><br><span class="line">    c_org = label_org.clone()</span><br><span class="line">    c_trg = label_trg.clone()</span><br><span class="line"><span class="keyword">elif</span> self.dataset == <span class="string">&#x27;RaFD&#x27;</span>:</span><br><span class="line">    c_org = self.label2onehot(label_org, self.c_dim)</span><br><span class="line">    c_trg = self.label2onehot(label_trg, self.c_dim)</span><br></pre></td></tr></table></figure>
<h2 id="5-3-train-G-and-D"><a href="#5-3-train-G-and-D" class="headerlink" title="5.3 train G and D"></a>5.3 train G and D</h2><h3 id="5-3-1-train-D"><a href="#5-3-1-train-D" class="headerlink" title="5.3.1 train D"></a>5.3.1 train D</h3><p>这里需要对上述提到的损失函数做进一步处理。</p>
<p><strong>判断图片真假损失</strong>:由方程6得：</p>
<script type="math/tex; mode=display">L_{adv}=-D_{src}(x)+D_{src}(G(x,c))+\lambda_{gp}(\parallel \nabla_{\hat{x}}  D_{src}(\hat{x}) \parallel_2-1)^2 \tag{7}</script><script type="math/tex; mode=display">\lambda_{gp}=10</script><p><strong>判断原图片属性正确</strong>:由方程2得：</p>
<script type="math/tex; mode=display">L_{cls}^r=D_{cls}(c'|x) \tag{8}</script><p><strong>总损失</strong>：</p>
<script type="math/tex; mode=display">L_D=-L_{adv}+\lambda_{cls} L_{cls}^r</script><script type="math/tex; mode=display">\lambda_{cls}=1</script><p><strong>备注</strong>：</p>
<ul>
<li>在计算真假损失的时候，是直接求输出的均值，这一点不是很理解。</li>
<li>方程7的第三项的计算见gradient_penalty，对整个图片的梯度求和。</li>
<li>方程8的的求解见classification_loss，就是一个简单的分类损失。</li>
<li>不理解方程2为什么要加个符号？方程7也是符号正好相反？</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># =================================================================================== #</span></span><br><span class="line"><span class="comment">#                             2. Train the discriminator                              #</span></span><br><span class="line"><span class="comment"># =================================================================================== #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute loss with real images.</span></span><br><span class="line">out_src, out_cls = self.D(x_real) <span class="comment"># out_src：N,1,2,2; out_cls: N,c_dim</span></span><br><span class="line">d_loss_real = - torch.mean(out_src) <span class="comment"># 方程7的第一项</span></span><br><span class="line">d_loss_cls = self.classification_loss(out_cls, label_org, self.dataset) <span class="comment"># 方程8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute loss with fake images.</span></span><br><span class="line">x_fake = self.G(x_real, c_trg)</span><br><span class="line">out_src, out_cls = self.D(x_fake.detach())</span><br><span class="line">d_loss_fake = torch.mean(out_src) <span class="comment"># 方程7的第二项</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute loss for gradient penalty.</span></span><br><span class="line">alpha = torch.rand(x_real.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).to(self.device)</span><br><span class="line">x_hat = (alpha * x_real.data + (<span class="number">1</span> - alpha) * x_fake.data).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">out_src, _ = self.D(x_hat)</span><br><span class="line">d_loss_gp = self.gradient_penalty(out_src, x_hat) <span class="comment"># 方程7的第三项</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Backward and optimize.</span></span><br><span class="line">d_loss = d_loss_real + d_loss_fake + self.lambda_cls * d_loss_cls + self.lambda_gp * d_loss_gp <span class="comment"># 总损失</span></span><br><span class="line">self.reset_grad()</span><br><span class="line">d_loss.backward()</span><br><span class="line">self.d_optimizer.step()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_penalty</span>(<span class="params">self, y, x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute gradient penalty: (L2_norm(dy/dx) - 1)**2.&quot;&quot;&quot;</span></span><br><span class="line">    weight = torch.ones(y.size()).to(self.device)</span><br><span class="line">    dydx = torch.autograd.grad(outputs=y,</span><br><span class="line">                                inputs=x,</span><br><span class="line">                                grad_outputs=weight,</span><br><span class="line">                                retain_graph=<span class="literal">True</span>,</span><br><span class="line">                                create_graph=<span class="literal">True</span>,</span><br><span class="line">                                only_inputs=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    dydx = dydx.view(dydx.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    dydx_l2norm = torch.sqrt(torch.<span class="built_in">sum</span>(dydx**<span class="number">2</span>, dim=<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> torch.mean((dydx_l2norm-<span class="number">1</span>)**<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">classification_loss</span>(<span class="params">self, logit, target, dataset=<span class="string">&#x27;CelebA&#x27;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute binary or softmax cross entropy loss.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> dataset == <span class="string">&#x27;CelebA&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> F.binary_cross_entropy_with_logits(logit, target, size_average=<span class="literal">False</span>) / logit.size(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">elif</span> dataset == <span class="string">&#x27;RaFD&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> F.cross_entropy(logit, target)</span><br></pre></td></tr></table></figure>
<h3 id="5-3-2-train-G"><a href="#5-3-2-train-G" class="headerlink" title="5.3.2 train G"></a>5.3.2 train G</h3><p>与以往训练几个G之后才训练D不同，这里是训练几个D之后才训练G。</p>
<p>同样对上述提到的损失做进一步处理。</p>
<p><strong>生成图片为真</strong>：由方程6得，与方程7正好相反：</p>
<script type="math/tex; mode=display">L_{adv}=-D_{src}(G(x,c)) \tag{9}</script><p><strong>生成图片的属性正确</strong>：由方程3得：</p>
<script type="math/tex; mode=display">L_{cls}^f=D_{cls}(c|G(x,c)) \tag{10}</script><p><strong>Reconstruction Loss</strong>: 重构损失</p>
<script type="math/tex; mode=display">L_{rec}=\parallel x-G(G(x,c),c') \parallel _1  \tag{4}</script><p><strong>总损失</strong></p>
<script type="math/tex; mode=display">L_G=L_{adv}+\lambda_{cls} L_{cls}^f+\lambda_{rec}L_{rec} \tag{5}</script><script type="math/tex; mode=display">\lambda_{cls}=1, \lambda_{rec}=10</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># =================================================================================== #</span></span><br><span class="line"><span class="comment">#                               3. Train the generator                                #</span></span><br><span class="line"><span class="comment"># =================================================================================== #</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (i+<span class="number">1</span>) % self.n_critic == <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># Original-to-target domain.</span></span><br><span class="line">    x_fake = self.G(x_real, c_trg)</span><br><span class="line">    out_src, out_cls = self.D(x_fake)</span><br><span class="line">    g_loss_fake = - torch.mean(out_src) <span class="comment"># 方程9</span></span><br><span class="line">    g_loss_cls = self.classification_loss(out_cls, label_trg, self.dataset) <span class="comment"># 方程10</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Target-to-original domain.</span></span><br><span class="line">    x_reconst = self.G(x_fake, c_org)</span><br><span class="line">    g_loss_rec = torch.mean(torch.<span class="built_in">abs</span>(x_real - x_reconst))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward and optimize.</span></span><br><span class="line">    g_loss = g_loss_fake + self.lambda_rec * g_loss_rec + self.lambda_cls * g_loss_cls</span><br><span class="line">    self.reset_grad()</span><br><span class="line">    g_loss.backward()</span><br><span class="line">    self.g_optimizer.step()</span><br></pre></td></tr></table></figure>
<h2 id="5-4-val"><a href="#5-4-val" class="headerlink" title="5.4 val"></a>5.4 val</h2><p><strong>CelebA数据集：</strong>这里制作target domain label的方法分为头发属性(互相排斥)和其他属性(不排斥):对于选中的头发属性’Black_Hair’, ‘Blond_Hair’, ‘Brown_Hair’,则把5张图片的’Black_Hair’全部设为1,’Blond_Hair’, ‘Brown_Hair’设为0,作为第一个target domain label, 再把5张图片的’Blond_Hair’全部设为1,’Black_Hair’, ‘Brown_Hair’设为0,作为第二个target domain label, 再把5张图片的’Brown_Hair’全部设为1,’Black_Hair’,’Blond_Hair’ 设为0,作为第三个target domain label,对于其他属性,则直接取相反数做为第三个target domain label和第四个target domain label.</p>
<p><strong>RaFD数据集</strong>:属于排斥属性，也和头发类似，对某一列全部设为1，其余设为0.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">c_org</span><br><span class="line">Out[<span class="number">24</span>]: </span><br><span class="line">tensor([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">        [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line"></span><br><span class="line">c_trg_list</span><br><span class="line">Out[<span class="number">25</span>]: </span><br><span class="line">[tensor([[ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>),</span><br><span class="line"> tensor([[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>),</span><br><span class="line"> tensor([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>),</span><br><span class="line"> tensor([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>),</span><br><span class="line"> tensor([[ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>)]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_labels</span>(<span class="params">self, c_org, c_dim=<span class="number">5</span>, dataset=<span class="string">&#x27;CelebA&#x27;</span>, selected_attrs=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Generate target domain labels for debugging and testing.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Get hair color indices.</span></span><br><span class="line">    <span class="keyword">if</span> dataset == <span class="string">&#x27;CelebA&#x27;</span>:</span><br><span class="line">        hair_color_indices = []</span><br><span class="line">        <span class="keyword">for</span> i, attr_name <span class="keyword">in</span> <span class="built_in">enumerate</span>(selected_attrs):</span><br><span class="line">            <span class="keyword">if</span> attr_name <span class="keyword">in</span> [<span class="string">&#x27;Black_Hair&#x27;</span>, <span class="string">&#x27;Blond_Hair&#x27;</span>, <span class="string">&#x27;Brown_Hair&#x27;</span>, <span class="string">&#x27;Gray_Hair&#x27;</span>]:</span><br><span class="line">                hair_color_indices.append(i)</span><br><span class="line"></span><br><span class="line">    c_trg_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(c_dim):</span><br><span class="line">        <span class="keyword">if</span> dataset == <span class="string">&#x27;CelebA&#x27;</span>:</span><br><span class="line">            c_trg = c_org.clone()</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> hair_color_indices:  <span class="comment"># Set one hair color to 1 and the rest to 0.</span></span><br><span class="line">                c_trg[:, i] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> hair_color_indices:</span><br><span class="line">                    <span class="keyword">if</span> j != i:</span><br><span class="line">                        c_trg[:, j] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                c_trg[:, i] = (c_trg[:, i] == <span class="number">0</span>)  <span class="comment"># Reverse attribute value.</span></span><br><span class="line">        <span class="keyword">elif</span> dataset == <span class="string">&#x27;RaFD&#x27;</span>:</span><br><span class="line">            c_trg = self.label2onehot(torch.ones(c_org.size(<span class="number">0</span>))*i, c_dim)</span><br><span class="line"></span><br><span class="line">        c_trg_list.append(c_trg.to(self.device))</span><br><span class="line">    <span class="keyword">return</span> c_trg_list</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fetch fixed inputs for debugging.</span></span><br><span class="line">data_iter = <span class="built_in">iter</span>(data_loader)</span><br><span class="line">x_fixed, c_org = <span class="built_in">next</span>(data_iter)</span><br><span class="line">x_fixed = x_fixed.to(self.device)</span><br><span class="line">c_fixed_list = self.create_labels(c_org, self.c_dim, self.dataset, self.selected_attrs)</span><br></pre></td></tr></table></figure>
<h2 id="5-5-多数据集"><a href="#5-5-多数据集" class="headerlink" title="5.5 多数据集"></a>5.5 多数据集</h2><p>在多数据集的情况下，损失函数大体不变，略微不同。</p>
<h3 id="5-5-1-input"><a href="#5-5-1-input" class="headerlink" title="5.5.1 input"></a>5.5.1 input</h3><p>多数据集顺序输入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> [<span class="string">&#x27;CelebA&#x27;</span>, <span class="string">&#x27;RaFD&#x27;</span>]:</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">celeba_iter = <span class="built_in">iter</span>(self.celeba_loader)</span><br><span class="line">x_real, label_org = <span class="built_in">next</span>(celeba_iter)</span><br><span class="line">rand_idx = torch.randperm(label_org.size(<span class="number">0</span>))</span><br><span class="line">label_trg = label_org[rand_idx]</span><br><span class="line"><span class="keyword">if</span> dataset == <span class="string">&#x27;CelebA&#x27;</span>:</span><br><span class="line">    c_org = label_org.clone()</span><br><span class="line">    c_trg = label_trg.clone()</span><br><span class="line">    zero = torch.zeros(x_real.size(<span class="number">0</span>), self.c2_dim)</span><br><span class="line">    mask = self.label2onehot(torch.zeros(x_real.size(<span class="number">0</span>)), <span class="number">2</span>)</span><br><span class="line">    c_org = torch.cat([c_org, zero, mask], dim=<span class="number">1</span>)</span><br><span class="line">    c_trg = torch.cat([c_trg, zero, mask], dim=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">elif</span> dataset == <span class="string">&#x27;RaFD&#x27;</span>:</span><br><span class="line">    c_org = self.label2onehot(label_org, self.c2_dim)</span><br><span class="line">    c_trg = self.label2onehot(label_trg, self.c2_dim)</span><br><span class="line">    zero = torch.zeros(x_real.size(<span class="number">0</span>), self.c_dim)</span><br><span class="line">    mask = self.label2onehot(torch.ones(x_real.size(<span class="number">0</span>)), <span class="number">2</span>)</span><br><span class="line">    c_org = torch.cat([zero, c_org, mask], dim=<span class="number">1</span>)</span><br><span class="line">    c_trg = torch.cat([zero, c_trg, mask], dim=<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="5-5-2-train-D-and-G"><a href="#5-5-2-train-D-and-G" class="headerlink" title="5.5.2 train D and G"></a>5.5.2 train D and G</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># =================================================================================== #</span></span><br><span class="line"><span class="comment">#                             2. Train the discriminator                              #</span></span><br><span class="line"><span class="comment"># =================================================================================== #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute loss with real images.</span></span><br><span class="line">out_src, out_cls = self.D(x_real) </span><br><span class="line">out_cls = out_cls[:, :self.c_dim] <span class="keyword">if</span> dataset == <span class="string">&#x27;CelebA&#x27;</span> <span class="keyword">else</span> out_cls[:, self.c_dim:] <span class="comment"># 属性损失只考虑一半</span></span><br><span class="line">d_loss_real = - torch.mean(out_src) <span class="comment"># 方程7的第一项</span></span><br><span class="line">d_loss_cls = self.classification_loss(out_cls, label_org, dataset) <span class="comment"># 方程8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute loss with fake images.</span></span><br><span class="line">x_fake = self.G(x_real, c_trg)</span><br><span class="line">out_src, _ = self.D(x_fake.detach())</span><br><span class="line">d_loss_fake = torch.mean(out_src) <span class="comment"># 方程7的第二项</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute loss for gradient penalty.</span></span><br><span class="line">alpha = torch.rand(x_real.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).to(self.device)</span><br><span class="line">x_hat = (alpha * x_real.data + (<span class="number">1</span> - alpha) * x_fake.data).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">out_src, _ = self.D(x_hat)</span><br><span class="line">d_loss_gp = self.gradient_penalty(out_src, x_hat) <span class="comment"># 方程7的第三项</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Backward and optimize.</span></span><br><span class="line">d_loss = d_loss_real + d_loss_fake + self.lambda_cls * d_loss_cls + self.lambda_gp * d_loss_gp</span><br><span class="line">self.reset_grad()</span><br><span class="line">d_loss.backward()</span><br><span class="line">self.d_optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Logging.</span></span><br><span class="line">loss = &#123;&#125;</span><br><span class="line">loss[<span class="string">&#x27;D/loss_real&#x27;</span>] = d_loss_real.item()</span><br><span class="line">loss[<span class="string">&#x27;D/loss_fake&#x27;</span>] = d_loss_fake.item()</span><br><span class="line">loss[<span class="string">&#x27;D/loss_cls&#x27;</span>] = d_loss_cls.item()</span><br><span class="line">loss[<span class="string">&#x27;D/loss_gp&#x27;</span>] = d_loss_gp.item()</span><br><span class="line"></span><br><span class="line"><span class="comment"># =================================================================================== #</span></span><br><span class="line"><span class="comment">#                               3. Train the generator                                #</span></span><br><span class="line"><span class="comment"># =================================================================================== #</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (i+<span class="number">1</span>) % self.n_critic == <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># Original-to-target domain.</span></span><br><span class="line">    x_fake = self.G(x_real, c_trg)</span><br><span class="line">    out_src, out_cls = self.D(x_fake)</span><br><span class="line">    out_cls = out_cls[:, :self.c_dim] <span class="keyword">if</span> dataset == <span class="string">&#x27;CelebA&#x27;</span> <span class="keyword">else</span> out_cls[:, self.c_dim:] <span class="comment"># 生成图片的属性只考虑一半</span></span><br><span class="line">    g_loss_fake = - torch.mean(out_src)</span><br><span class="line">    g_loss_cls = self.classification_loss(out_cls, label_trg, dataset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Target-to-original domain.</span></span><br><span class="line">    x_reconst = self.G(x_fake, c_org)</span><br><span class="line">    g_loss_rec = torch.mean(torch.<span class="built_in">abs</span>(x_real - x_reconst))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward and optimize.</span></span><br><span class="line">    g_loss = g_loss_fake + self.lambda_rec * g_loss_rec + self.lambda_cls * g_loss_cls</span><br><span class="line">    self.reset_grad()</span><br><span class="line">    g_loss.backward()</span><br><span class="line">    self.g_optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Logging.</span></span><br><span class="line">    loss[<span class="string">&#x27;G/loss_fake&#x27;</span>] = g_loss_fake.item()</span><br><span class="line">    loss[<span class="string">&#x27;G/loss_rec&#x27;</span>] = g_loss_rec.item()</span><br><span class="line">    loss[<span class="string">&#x27;G/loss_cls&#x27;</span>] = g_loss_cls.item()</span><br></pre></td></tr></table></figure>
<h3 id="5-5-3-val-and-test"><a href="#5-5-3-val-and-test" class="headerlink" title="5.5.3 val and test"></a>5.5.3 val and test</h3><p>对当前图片生成两个数据集下不同属性的图片，也就是说，具有跨数据集生成图片的能力。</p>
<p><strong>val</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (i+<span class="number">1</span>) % self.sample_step == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        x_fake_list = [x_fixed]</span><br><span class="line">        <span class="keyword">for</span> c_fixed <span class="keyword">in</span> c_celeba_list:</span><br><span class="line">            c_trg = torch.cat([c_fixed, zero_rafd, mask_celeba], dim=<span class="number">1</span>)</span><br><span class="line">            x_fake_list.append(self.G(x_fixed, c_trg))</span><br><span class="line">        <span class="keyword">for</span> c_fixed <span class="keyword">in</span> c_rafd_list:</span><br><span class="line">            c_trg = torch.cat([zero_celeba, c_fixed, mask_rafd], dim=<span class="number">1</span>)</span><br><span class="line">            x_fake_list.append(self.G(x_fixed, c_trg))</span><br></pre></td></tr></table></figure>
<p><strong>test</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, (x_real, c_org) <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.celeba_loader):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Prepare input images and target domain labels.</span></span><br><span class="line">    x_real = x_real.to(self.device)</span><br><span class="line">    c_celeba_list = self.create_labels(c_org, self.c_dim, <span class="string">&#x27;CelebA&#x27;</span>, self.selected_attrs)</span><br><span class="line">    c_rafd_list = self.create_labels(c_org, self.c2_dim, <span class="string">&#x27;RaFD&#x27;</span>)</span><br><span class="line">    zero_celeba = torch.zeros(x_real.size(<span class="number">0</span>), self.c_dim).to(self.device)            <span class="comment"># Zero vector for CelebA.</span></span><br><span class="line">    zero_rafd = torch.zeros(x_real.size(<span class="number">0</span>), self.c2_dim).to(self.device)             <span class="comment"># Zero vector for RaFD.</span></span><br><span class="line">    mask_celeba = self.label2onehot(torch.zeros(x_real.size(<span class="number">0</span>)), <span class="number">2</span>).to(self.device)  <span class="comment"># Mask vector: [1, 0].</span></span><br><span class="line">    mask_rafd = self.label2onehot(torch.ones(x_real.size(<span class="number">0</span>)), <span class="number">2</span>).to(self.device)     <span class="comment"># Mask vector: [0, 1].</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Translate images.</span></span><br><span class="line">    x_fake_list = [x_real]</span><br><span class="line">    <span class="keyword">for</span> c_celeba <span class="keyword">in</span> c_celeba_list:</span><br><span class="line">        c_trg = torch.cat([c_celeba, zero_rafd, mask_celeba], dim=<span class="number">1</span>)</span><br><span class="line">        x_fake_list.append(self.G(x_real, c_trg))</span><br><span class="line">    <span class="keyword">for</span> c_rafd <span class="keyword">in</span> c_rafd_list:</span><br><span class="line">        c_trg = torch.cat([zero_celeba, c_rafd, mask_rafd], dim=<span class="number">1</span>)</span><br><span class="line">        x_fake_list.append(self.G(x_real, c_trg))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save the translated images.</span></span><br><span class="line">    x_concat = torch.cat(x_fake_list, dim=<span class="number">3</span>)</span><br><span class="line">    result_path = os.path.join(self.result_dir, <span class="string">&#x27;&#123;&#125;-images.jpg&#x27;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    save_image(self.denorm(x_concat.data.cpu()), result_path, nrow=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Saved real and fake images into &#123;&#125;...&#x27;</span>.<span class="built_in">format</span>(result_path))</span><br></pre></td></tr></table></figure>
<h1 id="6-其他"><a href="#6-其他" class="headerlink" title="6. 其他"></a>6. 其他</h1><p>通过代码,我们可以猜出,对于starGAN,每一个domain都是一个二值属性,这些属性可以是互相排斥的,例如头发颜色,可以是不互相排斥的,并且这里和CycleGAN还是有一些区别的,CycleGAN的domain是数据集,source domain 和 target domain是风马牛不相及的,source domain和target domain有自己的风格,例如map数据集,是没有真值的,有的只是深度网络提取出的特征和70*70patchGAN.但是starGAN中,生成的图片和原始图片是一个数据集的,并且这两张图片不是要求风格一样,感觉这能应用到person-reid中也是神奇.</p>
<p>在图片真假的分类损失中，之前的GAN都是使用True和False来表示，这次换了一个新公式直接mean，还有点难理解。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/GAN/" rel="tag"># GAN</a>
              <a href="/tags/starGAN/" rel="tag"># starGAN</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2018/12/17/CASN/" rel="prev" title="CASN">
      <i class="fa fa-chevron-left"></i> CASN
    </a></div>
      <div class="post-nav-item">
    <a href="/2018/12/26/GPU/" rel="next" title="GPU">
      GPU <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#0-%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">0. 前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Introduction"><span class="nav-number">2.</span> <span class="nav-text">1. Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Star-Generative-Adversarial-Networks"><span class="nav-number">3.</span> <span class="nav-text">2. Star Generative Adversarial Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Multi-Domain-Image-to-Image-Translation"><span class="nav-number">3.1.</span> <span class="nav-text">2.1  Multi-Domain Image-to-Image Translation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-Training-with-Multiple-Datasets"><span class="nav-number">3.2.</span> <span class="nav-text">2.2. Training with Multiple Datasets</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Implementation"><span class="nav-number">4.</span> <span class="nav-text">3. Implementation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Experiments"><span class="nav-number">5.</span> <span class="nav-text">4. Experiments</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-Baseline-Models"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 Baseline Models</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-Training"><span class="nav-number">5.2.</span> <span class="nav-text">4.2 Training</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-Results"><span class="nav-number">5.3.</span> <span class="nav-text">4.3 Results</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-%E4%BB%A3%E7%A0%81"><span class="nav-number">6.</span> <span class="nav-text">5. 代码</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-Model-G-and-D"><span class="nav-number">6.1.</span> <span class="nav-text">5.1 Model: G and D</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-input"><span class="nav-number">6.2.</span> <span class="nav-text">5.2 input</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-train-G-and-D"><span class="nav-number">6.3.</span> <span class="nav-text">5.3 train G and D</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-1-train-D"><span class="nav-number">6.3.1.</span> <span class="nav-text">5.3.1 train D</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-2-train-G"><span class="nav-number">6.3.2.</span> <span class="nav-text">5.3.2 train G</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-4-val"><span class="nav-number">6.4.</span> <span class="nav-text">5.4 val</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-5-%E5%A4%9A%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">6.5.</span> <span class="nav-text">5.5 多数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-1-input"><span class="nav-number">6.5.1.</span> <span class="nav-text">5.5.1 input</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-2-train-D-and-G"><span class="nav-number">6.5.2.</span> <span class="nav-text">5.5.2 train D and G</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-3-val-and-test"><span class="nav-number">6.5.3.</span> <span class="nav-text">5.5.3 val and test</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-%E5%85%B6%E4%BB%96"><span class="nav-number">7.</span> <span class="nav-text">6. 其他</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">TianJiajie</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">76</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">73</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">TianJiajie</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
