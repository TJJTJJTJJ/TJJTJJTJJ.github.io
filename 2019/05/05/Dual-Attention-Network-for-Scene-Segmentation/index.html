<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Dual Attention Network for Scene Segmentation | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="0. 前言这篇文章的重点在于 dual attention 的作用，并且attention的使用和之前看到的 SE block 还不太一样。dual attention 主要解决了全局依赖性，即其他位置的物体对当前位置的的物体的特征的影响。重点不是场景分割，自己也不是很懂分割的代码和实现，暂时对分割不做过多研究。  paper: CPVR2019: Dual Attention Network f">
<meta property="og:type" content="article">
<meta property="og:title" content="Dual Attention Network for Scene Segmentation">
<meta property="og:url" content="http://example.com/2019/05/05/Dual-Attention-Network-for-Scene-Segmentation/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="0. 前言这篇文章的重点在于 dual attention 的作用，并且attention的使用和之前看到的 SE block 还不太一样。dual attention 主要解决了全局依赖性，即其他位置的物体对当前位置的的物体的特征的影响。重点不是场景分割，自己也不是很懂分割的代码和实现，暂时对分割不做过多研究。  paper: CPVR2019: Dual Attention Network f">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-05-05T02:21:36.000Z">
<meta property="article:modified_time" content="2019-05-20T07:45:23.148Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="segmentation">
<meta property="article:tag" content="attention">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Dual-Attention-Network-for-Scene-Segmentation" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/05/05/Dual-Attention-Network-for-Scene-Segmentation/" class="article-date">
  <time class="dt-published" datetime="2019-05-05T02:21:36.000Z" itemprop="datePublished">2019-05-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/segmentation/">segmentation</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Dual Attention Network for Scene Segmentation
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h2><p>这篇文章的重点在于 dual attention 的作用，并且attention的使用和之前看到的 SE block 还不太一样。dual attention 主要解决了全局依赖性，即其他位置的物体对当前位置的的物体的特征的影响。重点不是场景分割，自己也不是很懂分割的代码和实现，暂时对分割不做过多研究。</p>
<ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1809.02983.pdf">CPVR2019: Dual Attention Network for Scene Segmentation</a></li>
<li>code: <a target="_blank" rel="noopener" href="https://github.com/junfu1115/DANet/">pytorch</a></li>
<li>team: 中科院自动化所图像与视频分析团队（IVA），隶属于模式识别国家重点实验室，在 ICCV 2017 COCO-Places 场景解析竞赛、京东 AI 时尚挑战赛和阿里巴巴大规模图像搜索大赛踢馆赛等多次拔得头筹。嗯，一句话，很牛逼。</li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/P_LarT/article/details/89043620">解读</a></li>
</ul>
<span id="more"></span>

<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>作者提出了 <strong>Dual Attention Network(DANet)</strong> 来融合局部特征。具体的过程是在 dilated FCN 上添加了两种 attention modules: <strong>the position attention module</strong> and <strong>the channel attention module</strong>，这两个attention主要解决的是全局依赖性。</p>
<p>场景分割需要解决的两个问题：区分相似的东西(田地和草)，识别不同大小外观的同一个东西(车)。因此，场景分割模型需要提高像素级别识别的特征表示。</p>
<p>一种方法是<strong>多尺度</strong>融合来识别不同大小的物体，但是不能以全局地角度来很好地处理物体与物体之间的关系。应该是指最后的特征的感受野有大有小，可以理解成不同大小的物体都能识别到。</p>
<p>还有一种方法是利用了LSTM来实现 long-range dependencies，可以理解成物体的识别不仅依靠自己的特征，还依赖于其他物体的的特征，即<strong>全局依赖</strong>或者<strong>空间依赖性</strong>。</p>

<p>其中 the position attention module 主要用于解决全局的空间位置依赖问题，the channel attention module 解决的是全局的通道依赖性。</p>
<p>所以作者主要解决的是全局依赖性，并没有考虑不同大小的物体的分割问题。</p>
<p>按照作者的说法，DANet 有两种作用：第一，可以避免显眼的大的物体的特征影响不起眼的小的物体的标签；第二，可以在一定程度上融合不同尺寸的物体的相似特征；第三，利用空间和通道的依懒性解决全局依赖问题。</p>
<h2 id="2-Dual-Attention-Network"><a href="#2-Dual-Attention-Network" class="headerlink" title="2. Dual Attention Network"></a>2. Dual Attention Network</h2><h3 id="3-1-Overview"><a href="#3-1-Overview" class="headerlink" title="3.1 Overview"></a>3.1 Overview</h3><p>基准网络是 dilated FCN.</p>
<h3 id="3-2-Position-Attention-Module"><a href="#3-2-Position-Attention-Module" class="headerlink" title="3.2 Position Attention Module"></a>3.2 Position Attention Module</h3>

<p>通过特征提取网络得到特征图 $A\in R^{C\times H\times W}$，分别通过一个卷积层得两个特征图 $\lbrace B,C \rbrace \in R^{C\times H\times W}$，并且 reshape 成 $R^{C\times N}$，其中$N&#x3D;H\times W$，然后得到$S\in R^{N\times N}$，此时把$R^{C}$看成这个位置的特征。下面阐述下具体的过程：<br>$$\begin{aligned}<br>\hat{S}&amp;&#x3D;C^T\times B, (where, \hat{S}\in R^{N\times N}) \<br>       &amp;&#x3D;[C_1, C_2,…, C_N]^T\times [B_1, B_2,…, B_N] \<br>       &amp;&#x3D;\begin{bmatrix}<br>        C_1^T\times B_1 &amp; C_1^T\times B_2 &amp; … &amp; C_1^T\times B_N \<br>        C_2^T\times B_1 &amp; C_2^T\times B_2 &amp; … &amp; C_2^T\times B_N \<br>        … &amp; … &amp; … &amp; … \<br>        C_N^T\times B_1 &amp; C_N^T\times B_2 &amp; … &amp; C_N^T\times B_N<br>       \end{bmatrix}(where,C_j,B_i\in R^C)       \<br>\hat{s}<em>{ji}&amp;&#x3D;B_i^T \times C_j<br>\end{aligned}$$<br>从而得到$S$<br>$$s</em>{ji}&#x3D;\frac{\exp(B_i \cdot C_j)}{\sum_{i&#x3D;1}^N \exp(B_i \cdot C_j)}$$<br>可以理解成对$\hat{S}$的每一行都做一次softmax，即 S 的每一行和为1，可以解释成C中的点与B中所有点的相似性，越相似值越大。其中B和C是对称的。</p>
<p>同时，将A送进第三个滤波器得到 $D\in R^{C\times H\times W}$ 并且 reshape 成 $R^{C\times N}$ ，从而得到最后的输出$E$，下面阐述具体计算过程:<br>$$\begin{aligned}<br>\hat{E}&amp;&#x3D;D\times S^T (where,\hat{E}\in R^{C\times N}, D\in R^{C\times N}, C\in R^{N\times N})\<br>       &amp;&#x3D;[D_1, D_2,…, D_N] \times \begin{bmatrix}<br>        s_{11} &amp; s_{12} &amp; … &amp; s_{1N} \<br>        s_{21} &amp; s_{22} &amp; … &amp; s_{2N} \<br>        … &amp; … &amp; … &amp; … \<br>        s_{N1} &amp; s_{N2} &amp; … &amp; s_{NN}<br>       \end{bmatrix}^T(where,D_i\in R^C) \<br>       &amp;&#x3D;[D_1\cdot s_{11}+D_2\cdot s_{12}+…+D_N\cdot s_{1N}, …, D_1\cdot s_{N1}+D_2\cdot s_{N2}+…+D_N\cdot s_{NN}] \<br>       &amp;&#x3D;[\sum_i s_{1i}D_i, \sum_i s_{2i}D_i,… ,\sum_i s_{Ni}D_i] \<br>\hat{e}<em>{j}&amp;&#x3D;\sum_i^N(s</em>{ji}D_i)<br>\end{aligned}$$<br>从而得到$E\in R^{C\times N}$,<br>$$E_j&#x3D;\alpha \sum_i^N(s_{ji}D_i)+A_j$$<br>相当于 $\hat{E}$ 与 $A$ 进行了线性组合，并对其reshape变成$E\in R^{C\times H\times W}$，其中$\alpha$是一个可学习参数，网络自动学习，初始化为0。</p>
<p>如果不考虑其中的 softmax, 可以写成:<br>$$E&#x3D;\alpha D\times (C^T \times B)^T+A$$</p>
<h3 id="3-3-Channel-Attention-Module"><a href="#3-3-Channel-Attention-Module" class="headerlink" title="3.3 Channel Attention Module"></a>3.3 Channel Attention Module</h3><p>Position Attention Module 是把每个位置的通道作为其特征 $R^C$ ，Channel Attention Module 是把每个通道的特征图作为其特征 $R^N$。</p>
<p>与 Position Attention Module 不同的地方还有没有经过三个滤波器得到 $B,C,D$ ，而是直接使用A。</p>
<p>仍然是先把 A reshape 成 $A\in R^{C\times N}$，然后进行和上述类似的操作，可以令$B,C,D&#x3D;A^T$下面阐述具体过程:<br>$$\begin{aligned}<br>\hat{X}&amp;&#x3D;A\cdot A^T (where, A\in R^{C\times N}, X\in R^{C\times C}) \<br>\hat{x}<em>{ji}&amp;&#x3D;A_i^T \cdot A_j (where, A_i \in R^N)<br>\end{aligned}$$<br>结合后面的代码分析，从而得到$X\in R^{C\times C}$:<br>$$x</em>{ji}&#x3D;\frac{\exp(-A_i \cdot A_j)}{\sum_{i&#x3D;1}^N \exp(-A_i \cdot A_j)}$$<br>同样可以理解成对 $\hat{X}$ 的每一行做一次softmax，可以理解成A的自相关性。结合后面的 channel attention 的可视化，不同通道代表的类别不同，所以这里应该是越不相似值越大。</p>
<p>然后类似地我们得到$E\in R^{C\times H \times W}$:<br>$$E_j&#x3D;\beta \sum_i^N(x_{ji}A_i)+A_j$$</p>
<p>如果不考虑其中的 softmax, 可以写成:<br>$$E&#x3D;\beta (A \times A^T)\times A+A$$</p>
<p>这里给我的感觉更多地是在加法，而不是 SE block 用的乘法。</p>
<p>其实看到这里我是表示很怀疑的，这种 attention 能有效果吗？后面的可视化证明了作者的思路是正确的。</p>
<p>其中$\beta$也是一个可学习参数，网络自动学习，初始化为0。</p>
<h2 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4. Experiments"></a>4. Experiments</h2><h3 id="4-1-Implementation-Details"><a href="#4-1-Implementation-Details" class="headerlink" title="4.1 Implementation Details"></a>4.1 Implementation Details</h3><p>学习率: 多项式衰减<br>$$(1-\frac{iter}{total iter})^{0.9}$$</p>
<p>下面专门做一个学习率衰减的情况。</p>
<h3 id="4-2-Results-on-Datasets"><a href="#4-2-Results-on-Datasets" class="headerlink" title="4.2 Results on Datasets"></a>4.2 Results on Datasets</h3><h4 id="4-2-1-Ablation-Study-for-Attention-Modules"><a href="#4-2-1-Ablation-Study-for-Attention-Modules" class="headerlink" title="4.2.1 Ablation Study for Attention Modules"></a>4.2.1 Ablation Study for Attention Modules</h4>


<p>从实验结果可以看出， the position module 和 the channel module 互为补充，两个合起来后的提升效果没有单个的提升效果明显。</p>
<h3 id="4-2-3-Visualization-of-Attention-Module"><a href="#4-2-3-Visualization-of-Attention-Module" class="headerlink" title="4.2.3 Visualization of Attention Module"></a>4.2.3 Visualization of Attention Module</h3><p>这一小节很有意思的。</p>


<p>对于 position attention，得到的 $E\in R^{(H\times W)\times (H\times W)}$ ，可以理解点与点之间的相似性，对每个图片，选两个点，记为 ( #1 and #2 )，并且展示这两个点的 position attention map. 第一张图 #1 标记的是建筑物， #2 标记的是车，第二张图分别标记的是交通标记和行人，第三行标记的是植物和行人。可以看出来，同一类事物哪怕离得远也可以标记出来，不同事物哪怕离得近也标记不出来。或者说， position attention 具有在全局的角度来标记同一类事物，哪怕离得远，哪怕事物很小，同时区分近距离的不同事物。</p>
<p>对于 channel attention, 从图片中可以看出来，主要是同一通道得到的是同一类别。</p>
<p>现在还不知道是怎么可视化的。</p>
<h3 id="4-2-4-Comparing-with-State-of-the-art"><a href="#4-2-4-Comparing-with-State-of-the-art" class="headerlink" title="4.2.4 Comparing with State-of-the-art"></a>4.2.4 Comparing with State-of-the-art</h3>

<p>嗯，比其他方法都强。</p>
<p>作者一共在四个数据集上做了实验，说明是真的强。</p>
<h2 id="5-Learning-rate"><a href="#5-Learning-rate" class="headerlink" title="5. Learning rate"></a>5. Learning rate</h2><p>以前虽然一直在用一些学习率衰减方式，但是都不系统。</p>
<h3 id="5-1-fixed"><a href="#5-1-fixed" class="headerlink" title="5.1 fixed"></a>5.1 fixed</h3><p>$$lr&#x3D;base_lr$$</p>
<h3 id="5-2-step"><a href="#5-2-step" class="headerlink" title="5.2 step"></a>5.2 step</h3><p>离散的学习率变化策略<br>$$lr&#x3D;base_lr\cdot \gamma^{epoch&#x2F;&#x2F;step_size}$$<br>其中，向下取整，并且 $\gamma$ 和 step_size 都需要设置</p>

<p>gamma一般取0.1， step_wise一般取40</p>
<h3 id="5-3-exp"><a href="#5-3-exp" class="headerlink" title="5.3 exp"></a>5.3 exp</h3><p>$$lr&#x3D;base_lr\cdot \gamma^{epoch}$$<br>其中 $\gamma$ 需要设置</p>

<p>gamma一般取0.99</p>
<h3 id="5-4-inv"><a href="#5-4-inv" class="headerlink" title="5.4 inv"></a>5.4 inv</h3><p>$$lr&#x3D;base_lr\cdot (1+y\cdot epoch)^{-power}$$<br>其中$\gamma$和power都需要设置</p>

<p>gamma控制下降速率，power控制曲线在饱和状态下学习率达到的最低值。可以理解成当epoch达到最大值的时候，学习率在不同的power下最低值不一样。</p>
<h3 id="5-5-multistep"><a href="#5-5-multistep" class="headerlink" title="5.5 multistep"></a>5.5 multistep</h3><p>多次step，只是学习率改变的迭代次数不均匀</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lr_policy: <span class="string">&quot;multistep&quot;</span></span><br><span class="line">gamma: <span class="number">0.5</span></span><br><span class="line">stepvalue: <span class="number">10000</span></span><br><span class="line">stepvalue: <span class="number">30000</span></span><br><span class="line">stepvalue: <span class="number">60000</span></span><br></pre></td></tr></table></figure>

<h3 id="5-6-poly"><a href="#5-6-poly" class="headerlink" title="5.6 poly"></a>5.6 poly</h3><p>$$lr&#x3D;base_lr\cdot (1-epoch&#x2F;max_epoch)^{power}$$<br>其中，power需要设置，并且epoch为0时，lr是base_lr，当达到最大次数时，学习率变成0.</p>


<h3 id="5-7-sigmoid"><a href="#5-7-sigmoid" class="headerlink" title="5.7 sigmoid"></a>5.7 sigmoid</h3><p>$$lr&#x3D;base_lr\cdot \frac{1}{1+exp^{-\gamma \cdot (epoch-step_size)}}$$</p>

<p>其中step_size控制sigmoid为0.5的位置，gamma学习率的变化速率。</p>
<h3 id="5-8-warm-up"><a href="#5-8-warm-up" class="headerlink" title="5.8 warm up"></a>5.8 warm up</h3><p>在前10个epoch使用较小的lr，之后正常使用</p>
<h3 id="5-9-all"><a href="#5-9-all" class="headerlink" title="5.9 all"></a>5.9 all</h3>

<p>其中，step和multi_step最好，其次是exp,ploy，最差的是 inv,sigmoid.</p>
<h3 id="5-10-code"><a href="#5-10-code" class="headerlink" title="5.10 code"></a>5.10 code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">x = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1000</span>))</span><br><span class="line">base_lr=<span class="number">0.01</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">step_lr</span>(<span class="params">epoch</span>):</span><br><span class="line">    step_wise=<span class="number">50</span></span><br><span class="line">    gamma=<span class="number">0.1</span></span><br><span class="line">    <span class="keyword">return</span> base_lr*gamma**(epoch//step_wise)</span><br><span class="line">y = [step_lr(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">plt.plot(x,y)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exp_lr</span>(<span class="params">epoch</span>):</span><br><span class="line">    gamma=<span class="number">0.999</span></span><br><span class="line">    <span class="keyword">return</span> base_lr*gamma**epoch</span><br><span class="line">y = [exp_lr(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">plt.plot(x,y)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">inv_lr</span>(<span class="params">epoch</span>):</span><br><span class="line">    gamma=<span class="number">0.1</span></span><br><span class="line">    power=<span class="number">0.75</span></span><br><span class="line">    <span class="keyword">return</span> base_lr*(<span class="number">1</span>+gamma*epoch)**(-power)</span><br><span class="line">y = [inv_lr(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">plt.plot(x,y)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multi_lr</span>(<span class="params">epoch</span>):</span><br><span class="line">    step_wise1=<span class="number">200</span></span><br><span class="line">    step_wise2=<span class="number">300</span></span><br><span class="line">    step_wise3=<span class="number">400</span></span><br><span class="line">    gamma=<span class="number">0.5</span></span><br><span class="line">    power = [<span class="number">0</span>]*step_wise1 + [<span class="number">1</span>]*step_wise2+[<span class="number">2</span>]*step_wise3</span><br><span class="line">    <span class="keyword">if</span> epoch&lt;<span class="built_in">len</span>(power):</span><br><span class="line">        <span class="keyword">return</span> base_lr*gamma**power[epoch]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> base_lr*gamma**<span class="number">3</span></span><br><span class="line">y = [multi_lr(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">plt.plot(x,y)</span><br></pre></td></tr></table></figure>

<h2 id="6-code"><a href="#6-code" class="headerlink" title="6. code"></a>6. code</h2><p>这次的代码很有含金量，用到了多GPU。</p>
<p>一是涉及到的代码有点多，二是自己没有跑过分割的代码，不清楚具体的代码组织形式。所以下面从小到大一个个讲关键的地方。有些代码和作者的论文描述不是非常一致，但不影响总体。</p>
<h3 id="6-1-PAM-and-CAM"><a href="#6-1-PAM-and-CAM" class="headerlink" title="6.1 PAM and CAM"></a>6.1 PAM and CAM</h3><p>position attention and channel attention</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PAM_Module</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Position attention module&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#Ref from SAGAN</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(PAM_Module, self).__init__()</span><br><span class="line">        self.chanel_in = in_dim</span><br><span class="line"></span><br><span class="line">        self.query_conv = Conv2d(in_channels=in_dim, out_channels=in_dim//<span class="number">8</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.key_conv = Conv2d(in_channels=in_dim, out_channels=in_dim//<span class="number">8</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.value_conv = Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.gamma = Parameter(torch.zeros(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        self.softmax = Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            inputs :</span></span><br><span class="line"><span class="string">                x : input feature maps( B X C X H X W)</span></span><br><span class="line"><span class="string">            returns :</span></span><br><span class="line"><span class="string">                out : attention value + input feature</span></span><br><span class="line"><span class="string">                attention: B X (HxW) X (HxW)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># C: 512, C//8: 64</span></span><br><span class="line">        m_batchsize, C, height, width = x.size()</span><br><span class="line">        <span class="comment"># x: B,C,H,W</span></span><br><span class="line">        proj_query = self.query_conv(x).view(m_batchsize, -<span class="number">1</span>, width*height).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># C&#x27;: B,HxW,C//8</span></span><br><span class="line">        proj_key = self.key_conv(x).view(m_batchsize, -<span class="number">1</span>, width*height)</span><br><span class="line">        <span class="comment"># B: B,C//8,HxW</span></span><br><span class="line">        energy = torch.bmm(proj_query, proj_key)</span><br><span class="line">        <span class="comment"># \hat&#123;S&#125; = C&#x27;xB : B,HxW,HxW</span></span><br><span class="line">        attention = self.softmax(energy)</span><br><span class="line">        <span class="comment"># S: B,HxW,HxW</span></span><br><span class="line">        proj_value = self.value_conv(x).view(m_batchsize, -<span class="number">1</span>, width*height)</span><br><span class="line">        <span class="comment"># D: B,C,HxW</span></span><br><span class="line">        out = torch.bmm(proj_value, attention.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># \hat&#123;E&#125; = DxS&#x27;: B,C,HxW</span></span><br><span class="line">        out = out.view(m_batchsize, C, height, width)</span><br><span class="line">        <span class="comment"># \hat&#123;E&#125; : B,C,H,W</span></span><br><span class="line">        out = self.gamma*out + x</span><br><span class="line">        <span class="comment"># E: B,C,H,W</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CAM_Module</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Channel attention module&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(CAM_Module, self).__init__()</span><br><span class="line">        self.chanel_in = in_dim</span><br><span class="line">        self.gamma = Parameter(torch.zeros(<span class="number">1</span>))</span><br><span class="line">        self.softmax  = Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            inputs :</span></span><br><span class="line"><span class="string">                x : input feature maps( B X C X H X W)</span></span><br><span class="line"><span class="string">            returns :</span></span><br><span class="line"><span class="string">                out : attention value + input feature</span></span><br><span class="line"><span class="string">                attention: B X C X C</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        m_batchsize, C, height, width = x.size()</span><br><span class="line">        <span class="comment"># x: B,C,H,W</span></span><br><span class="line">        proj_query = x.view(m_batchsize, C, -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># A: B,C,HxW</span></span><br><span class="line">        proj_key = x.view(m_batchsize, C, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># A&#x27;: B,HxW,C</span></span><br><span class="line">        energy = torch.bmm(proj_query, proj_key)</span><br><span class="line">        <span class="comment"># \hat&#123;X&#125; = AxA&#x27;: B,C,C</span></span><br><span class="line">        energy_new = torch.<span class="built_in">max</span>(energy, -<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">0</span>].expand_as(energy)-energy</span><br><span class="line">        <span class="comment"># note that, 作者在这里用了一次 max-v_i，而不是常见的v_i-max，按照github上的解释，</span></span><br><span class="line">        <span class="comment"># 作者选用前者而不是后者的原因是后者的效果不好，不知道该怎么反驳，</span></span><br><span class="line">        <span class="comment"># channel attention 主要衡量的是通道与通道之间的相似性，</span></span><br><span class="line">        <span class="comment"># 按照这个公式，结合channel的可视化，只能强行解释成，希望通道之间不相似，越不相似给的值越高，</span></span><br><span class="line">        attention = self.softmax(energy_new)</span><br><span class="line">        <span class="comment"># X: B,C,C</span></span><br><span class="line">        proj_value = x.view(m_batchsize, C, -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># D: B,C,HxW</span></span><br><span class="line">        out = torch.bmm(attention, proj_value)</span><br><span class="line">        <span class="comment"># \hat&#123;E&#125; = XxD : B,C,HxW，这里也满足\hat&#123;E&#125;中的每个元素的系数之后为1</span></span><br><span class="line">        out = out.view(m_batchsize, C, height, width)</span><br><span class="line">        <span class="comment"># \hat&#123;E&#125;: B,C,H,W</span></span><br><span class="line">        out = self.gamma*out + x</span><br><span class="line">        <span class="comment"># E: B,C,H,W</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<h3 id="6-2-DANetHead"><a href="#6-2-DANetHead" class="headerlink" title="6.2 DANetHead"></a>6.2 DANetHead</h3><p>从代码上看，过程大概是：</p>
<ol>
<li>是在进入 attention module 会进行一次通道缩小，2048-&gt;512，</li>
<li>position attention module: sa_conv, channel attention module: sc_conv</li>
<li>得到三种预测的类别：sa_conv+sc_conv-&gt;sasc_output, sa_conv-&gt;sa_output, sc_conv-&gt;sc_output</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DANetHead</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, norm_layer</span>):</span><br><span class="line">        <span class="comment"># in_channels: 2048</span></span><br><span class="line">        <span class="comment"># out_channels: dataset.num_classes</span></span><br><span class="line">        <span class="built_in">super</span>(DANetHead, self).__init__()</span><br><span class="line">        inter_channels = in_channels // <span class="number">4</span></span><br><span class="line">        self.conv5a = nn.Sequential(nn.Conv2d(in_channels, inter_channels, <span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                                   norm_layer(inter_channels),</span><br><span class="line">                                   nn.ReLU())</span><br><span class="line">        self.sa = PAM_Module(inter_channels)</span><br><span class="line">        self.conv51 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, <span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                                   norm_layer(inter_channels),</span><br><span class="line">                                   nn.ReLU())</span><br><span class="line">        self.conv6 = nn.Sequential(nn.Dropout2d(<span class="number">0.1</span>, <span class="literal">False</span>), nn.Conv2d(<span class="number">512</span>, out_channels, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        self.conv5c = nn.Sequential(nn.Conv2d(in_channels, inter_channels, <span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                                   norm_layer(inter_channels),</span><br><span class="line">                                   nn.ReLU())</span><br><span class="line">        self.sc = CAM_Module(inter_channels)</span><br><span class="line">        self.conv52 = nn.Sequential(nn.Conv2d(inter_channels, inter_channels, <span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                                   norm_layer(inter_channels),</span><br><span class="line">                                   nn.ReLU())</span><br><span class="line">        self.conv7 = nn.Sequential(nn.Dropout2d(<span class="number">0.1</span>, <span class="literal">False</span>), nn.Conv2d(<span class="number">512</span>, out_channels, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        self.conv8 = nn.Sequential(nn.Dropout2d(<span class="number">0.1</span>, <span class="literal">False</span>), nn.Conv2d(<span class="number">512</span>, out_channels, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># x: B,C,H,W: C 2048</span></span><br><span class="line">        feat1 = self.conv5a(x)</span><br><span class="line">        <span class="comment"># feat1: B,C//4,H,W</span></span><br><span class="line">        sa_feat = self.sa(feat1)</span><br><span class="line">        <span class="comment"># sa_feat: B,C//4,H,W</span></span><br><span class="line">        sa_conv = self.conv51(sa_feat)</span><br><span class="line">        <span class="comment"># sa_conv: B,C//4,H,W</span></span><br><span class="line">        sa_output = self.conv6(sa_conv)</span><br><span class="line">        <span class="comment"># sa_output: B,C_out,H,W</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># x: B,C,H,W: C 2048</span></span><br><span class="line">        feat2 = self.conv5c(x)</span><br><span class="line">        <span class="comment"># feat2: B,C//4,H,W</span></span><br><span class="line">        sc_feat = self.sc(feat2)</span><br><span class="line">        <span class="comment"># sc_feat: B,C//4,H,W</span></span><br><span class="line">        sc_conv = self.conv52(sc_feat)</span><br><span class="line">        <span class="comment"># sc_conv: B,C//4,H,W</span></span><br><span class="line">        sc_output = self.conv7(sc_conv)</span><br><span class="line">        <span class="comment"># sc_output: B,C_out,H,W</span></span><br><span class="line"></span><br><span class="line">        feat_sum = sa_conv+sc_conv</span><br><span class="line">        <span class="comment"># feat_sum: B,C//4,H,W</span></span><br><span class="line">        sasc_output = self.conv8(feat_sum)</span><br><span class="line">        <span class="comment"># sasc_output: B,C_out,H,W</span></span><br><span class="line"></span><br><span class="line">        output = [sasc_output]</span><br><span class="line">        output.append(sa_output)</span><br><span class="line">        output.append(sc_output)</span><br><span class="line">        <span class="comment"># output:[sasc_output, sa_output, sc_output]: 3,B,C_out,H,W</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">tuple</span>(output)</span><br></pre></td></tr></table></figure>

<h3 id="6-3-BaseNet"><a href="#6-3-BaseNet" class="headerlink" title="6.3 BaseNet"></a>6.3 BaseNet</h3><p>以ResNet-50为例，相当于求得每一个layer的输出 [c1, c2, c3, c4]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BaseNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nclass, backbone, aux, se_loss, dilated=<span class="literal">True</span>, norm_layer=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 base_size=<span class="number">576</span>, crop_size=<span class="number">608</span>, mean=[<span class="number">.485</span>, <span class="number">.456</span>, <span class="number">.406</span>],</span></span><br><span class="line"><span class="params">                 std=[<span class="number">.229</span>, <span class="number">.224</span>, <span class="number">.225</span>], root=<span class="string">&#x27;./pretrain_models&#x27;</span>,</span></span><br><span class="line"><span class="params">                 multi_grid=<span class="literal">False</span>, multi_dilation=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BaseNet, self).__init__()</span><br><span class="line">        self.nclass = nclass</span><br><span class="line">        self.aux = aux</span><br><span class="line">        self.se_loss = se_loss</span><br><span class="line">        self.mean = mean</span><br><span class="line">        self.std = std</span><br><span class="line">        self.base_size = base_size</span><br><span class="line">        self.crop_size = crop_size</span><br><span class="line">        <span class="comment"># copying modules from pretrained models</span></span><br><span class="line">        <span class="keyword">if</span> backbone == <span class="string">&#x27;resnet50&#x27;</span>:</span><br><span class="line">            self.pretrained = resnet.resnet50(pretrained=<span class="literal">True</span>, dilated=dilated,</span><br><span class="line">                                              norm_layer=norm_layer, root=root,</span><br><span class="line">                                              multi_grid=multi_grid, multi_dilation=multi_dilation)</span><br><span class="line">        <span class="keyword">elif</span> backbone == <span class="string">&#x27;resnet101&#x27;</span>:</span><br><span class="line">            self.pretrained = resnet.resnet101(pretrained=<span class="literal">True</span>, dilated=dilated,</span><br><span class="line">                                               norm_layer=norm_layer, root=root,</span><br><span class="line">                                               multi_grid=multi_grid,multi_dilation=multi_dilation)</span><br><span class="line">        <span class="keyword">elif</span> backbone == <span class="string">&#x27;resnet152&#x27;</span>:</span><br><span class="line">            self.pretrained = resnet.resnet152(pretrained=<span class="literal">True</span>, dilated=dilated,</span><br><span class="line">                                               norm_layer=norm_layer, root=root,</span><br><span class="line">                                               multi_grid=multi_grid, multi_dilation=multi_dilation)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">&#x27;unknown backbone: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(backbone))</span><br><span class="line">        <span class="comment"># bilinear upsample options</span></span><br><span class="line">        self._up_kwargs = up_kwargs</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">base_forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.pretrained.conv1(x)</span><br><span class="line">        x = self.pretrained.bn1(x)</span><br><span class="line">        x = self.pretrained.relu(x)</span><br><span class="line">        x = self.pretrained.maxpool(x)</span><br><span class="line">        c1 = self.pretrained.layer1(x)</span><br><span class="line">        c2 = self.pretrained.layer2(c1)</span><br><span class="line">        c3 = self.pretrained.layer3(c2)</span><br><span class="line">        c4 = self.pretrained.layer4(c3)</span><br><span class="line">        <span class="keyword">return</span> c1, c2, c3, c4</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self, x, target=<span class="literal">None</span></span>):</span><br><span class="line">        pred = self.forward(x)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(pred, (<span class="built_in">tuple</span>, <span class="built_in">list</span>)):</span><br><span class="line">            pred = pred[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> target <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> pred</span><br><span class="line">        correct, labeled = batch_pix_accuracy(pred.data, target.data)</span><br><span class="line">        inter, union = batch_intersection_union(pred.data, target.data, self.nclass)</span><br><span class="line">        <span class="keyword">return</span> correct, labeled, inter, union</span><br></pre></td></tr></table></figure>

<h3 id="6-5-DANet"><a href="#6-5-DANet" class="headerlink" title="6.5 DANet"></a>6.5 DANet</h3><p>相当于求这三种的预测：sa_conv+sc_conv-&gt;sasc_output, sa_conv-&gt;sa_output, sc_conv-&gt;sc_output</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DANet</span>(<span class="title class_ inherited__">BaseNet</span>):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Fully Convolutional Networks for Semantic Segmentation</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    nclass : int</span></span><br><span class="line"><span class="string">        Number of categories for the training dataset.</span></span><br><span class="line"><span class="string">    backbone : string</span></span><br><span class="line"><span class="string">        Pre-trained dilated backbone network type (default:&#x27;resnet50&#x27;; &#x27;resnet50&#x27;,</span></span><br><span class="line"><span class="string">        &#x27;resnet101&#x27; or &#x27;resnet152&#x27;).</span></span><br><span class="line"><span class="string">    norm_layer : object</span></span><br><span class="line"><span class="string">        Normalization layer used in backbone network (default: :class:`mxnet.gluon.nn.BatchNorm`;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Long, Jonathan, Evan Shelhamer, and Trevor Darrell. &quot;Fully convolutional networks</span></span><br><span class="line"><span class="string">        for semantic segmentation.&quot; *CVPR*, 2015</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nclass, backbone, aux=<span class="literal">False</span>, se_loss=<span class="literal">False</span>, norm_layer=nn.BatchNorm2d, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(DANet, self).__init__(nclass, backbone, aux, se_loss, norm_layer=norm_layer, **kwargs)</span><br><span class="line">        self.head = DANetHead(<span class="number">2048</span>, nclass, norm_layer)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 具体的图片大小还是需要看图像分割的输入，这里以标准的224为例</span></span><br><span class="line">        <span class="comment"># x: 3,H,W &amp;&amp; 224, 224</span></span><br><span class="line">        imsize = x.size()[<span class="number">2</span>:]</span><br><span class="line">        _, _, c3, c4 = self.base_forward(x)</span><br><span class="line">        <span class="comment"># c3, c4: ResNet-50 的 layer3 和 layer 4 的输出</span></span><br><span class="line">        <span class="comment"># c3: 1024, H//16, W//16 &amp;&amp; 1024, 14, 14=224//16</span></span><br><span class="line">        <span class="comment"># c4: 2018, H//32, W//32 &amp;&amp; 7, 7=224//32</span></span><br><span class="line">        x = self.head(c4)</span><br><span class="line">        <span class="comment"># x: [sasc_output, sa_output, sc_output]: 3,B,dataset.num_classes,H//32, W//32 &amp;&amp; 7, 7=224//32</span></span><br><span class="line">        x = <span class="built_in">list</span>(x)</span><br><span class="line">        x[<span class="number">0</span>] = upsample(x[<span class="number">0</span>], imsize, **self._up_kwargs)</span><br><span class="line">        x[<span class="number">1</span>] = upsample(x[<span class="number">1</span>], imsize, **self._up_kwargs)</span><br><span class="line">        x[<span class="number">2</span>] = upsample(x[<span class="number">2</span>], imsize, **self._up_kwargs)</span><br><span class="line">        <span class="comment"># 上采样</span></span><br><span class="line">        <span class="comment"># x: [sasc_output, sa_output, sc_output]: 3,B,dataset.num_classes,H,W &amp;&amp; 224, 224</span></span><br><span class="line">        outputs = [x[<span class="number">0</span>]]</span><br><span class="line">        outputs.append(x[<span class="number">1</span>])</span><br><span class="line">        outputs.append(x[<span class="number">2</span>])</span><br><span class="line">        <span class="comment"># x: [sasc_output, sa_output, sc_output]: 3,B,dataset.num_classes,H,W &amp;&amp; 224, 224</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">tuple</span>(outputs)</span><br></pre></td></tr></table></figure>

<h3 id="6-6-SegmentationMultiLosses"><a href="#6-6-SegmentationMultiLosses" class="headerlink" title="6.6 SegmentationMultiLosses"></a>6.6 SegmentationMultiLosses</h3><p>希望 position+channel attetion, position attention, channel attention 三种预测都准确</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SegmentationMultiLosses</span>(<span class="title class_ inherited__">CrossEntropyLoss</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;2D Cross Entropy Loss with Multi-L1oss&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nclass=-<span class="number">1</span>, weight=<span class="literal">None</span>,size_average=<span class="literal">True</span>, ignore_index=-<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SegmentationMultiLosses, self).__init__(weight, size_average, ignore_index)</span><br><span class="line">        self.nclass = nclass</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, *inputs</span>):</span><br><span class="line"></span><br><span class="line">        *preds, target = <span class="built_in">tuple</span>(inputs)</span><br><span class="line">        pred1, pred2 ,pred3= <span class="built_in">tuple</span>(preds)</span><br><span class="line">        <span class="comment"># sa_conv+sc_conv-&gt;sasc_output, sa_conv-&gt;sa_output, sc_conv-&gt;sc_output</span></span><br><span class="line">        loss1 = <span class="built_in">super</span>(SegmentationMultiLosses, self).forward(pred1, target)</span><br><span class="line">        loss2 = <span class="built_in">super</span>(SegmentationMultiLosses, self).forward(pred2, target)</span><br><span class="line">        loss3 = <span class="built_in">super</span>(SegmentationMultiLosses, self).forward(pred3, target)</span><br><span class="line">        loss = loss1 + loss2 + loss3</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="6-7-其他"><a href="#6-7-其他" class="headerlink" title="6.7 其他"></a>6.7 其他</h3><p>其他的代码暂时就不看了，只是记录一个自己没有看到过的函数</p>
<p>Synchronized Cross-GPU Batch Normalization functions</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/05/05/Dual-Attention-Network-for-Scene-Segmentation/" data-id="cla55fgcz000gwka74q4i3j3g" data-title="Dual Attention Network for Scene Segmentation" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/attention/" rel="tag">attention</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/segmentation/" rel="tag">segmentation</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/05/06/ECN/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          ECN
        
      </div>
    </a>
  
  
    <a href="/2019/05/04/SE-block/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">SE block</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/408/">408</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/408/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/">计算机组成原理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/408/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/DeepLearning/">DeepLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GAN/">GAN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GPU/">GPU</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Markdown/">Markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/VOS/">VOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/attention/">attention</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/cuda/">cuda</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep-learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/docker/">docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/face-recognition/">face recognition</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/github-markdown/">github-markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/html/">html</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ind1/">ind1</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/markdown/">markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/object-detection/">object detection</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/person-re-id/">person re-id</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/person-reid/">person-reid</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/preson-re-id/">preson re-id</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/pytorch/">pytorch</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/re-ID/">re-ID</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/re-id/">re-id</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/segmentation/">segmentation</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/semantice-segmentation/">semantice segmentation</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tensorboard/">tensorboard</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tensorflow/">tensorflow</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/unsupervised-video-object-segmentation/">unsupervised video object segmentation</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/unsupervised-video-object-segmentation/VOS/">VOS</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%B9%E5%99%A8/">容器</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/">搭建博客</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/408/">408</a></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/408/" rel="tag">408</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CMC/" rel="tag">CMC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GAN/" rel="tag">GAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Grad-CAM/" rel="tag">Grad-CAM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markdown/" rel="tag">Markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RotationNet/" rel="tag">RotationNet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SE/" rel="tag">SE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SPGAN/" rel="tag">SPGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VOS/" rel="tag">VOS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/a/" rel="tag">a</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/attention/" rel="tag">attention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/b/" rel="tag">b</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cross-domain/" rel="tag">cross domain</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cross-domain-person-re-id/" rel="tag">cross-domain person re-id</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cuda/" rel="tag">cuda</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cudnn/" rel="tag">cudnn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cycleGAN/" rel="tag">cycleGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data/" rel="tag">data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-VOS/" rel="tag">data_VOS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deep-learning/" rel="tag">deep-learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/domain-adaption/" rel="tag">domain adaption</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/domain-guided-distillation/" rel="tag">domain guided distillation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/driver/" rel="tag">driver</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/face-recognition/" rel="tag">face recognition</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/face-synthesis/" rel="tag">face synthesis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/few-shot/" rel="tag">few-shot</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/few-shot-learning/" rel="tag">few-shot learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/" rel="tag">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/github/" rel="tag">github</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/" rel="tag">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/html/" rel="tag">html</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/" rel="tag">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/markdown/" rel="tag">markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mask-and-colour/" rel="tag">mask and colour</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/math/" rel="tag">math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mathjax/" rel="tag">mathjax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memory/" rel="tag">memory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/meta-learning/" rel="tag">meta-learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/multi-domain/" rel="tag">multi-domain</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/network/" rel="tag">network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/neural-style-transfer/" rel="tag">neural style transfer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/npm/" rel="tag">npm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numpy/" rel="tag">numpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/object-detection/" rel="tag">object detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/one-example/" rel="tag">one_example</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paper/" rel="tag">paper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/person-re-id/" rel="tag">person re-id</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/person-re-identification/" rel="tag">person re-identification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/person-reid/" rel="tag">person-reid</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-picture/" rel="tag">python,picture</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytorch/" rel="tag">pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytorch-learn-chenyun/" rel="tag">pytorch-learn chenyun</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/re-ID/" rel="tag">re-ID</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/re-id/" rel="tag">re-id</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/segmentation/" rel="tag">segmentation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/semantice-segmentation/" rel="tag">semantice segmentation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sharelatex/" rel="tag">sharelatex</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/softmax/" rel="tag">softmax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/starGAN/" rel="tag">starGAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorboard/" rel="tag">tensorboard</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/" rel="tag">tensorflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/transfer-learning/" rel="tag">transfer learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%B7%E7%A7%AF-%E5%8F%8D%E5%8D%B7%E7%A7%AF-%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF/" rel="tag">卷积\反卷积 空洞卷积</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9F%BA%E7%A1%80/" rel="tag">基础</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%B9%E5%99%A8/" rel="tag">容器</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" rel="tag">计算机操作系统</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/408/" style="font-size: 15px;">408</a> <a href="/tags/CMC/" style="font-size: 10px;">CMC</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/GAN/" style="font-size: 20px;">GAN</a> <a href="/tags/Grad-CAM/" style="font-size: 10px;">Grad-CAM</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Markdown/" style="font-size: 10px;">Markdown</a> <a href="/tags/RotationNet/" style="font-size: 10px;">RotationNet</a> <a href="/tags/SE/" style="font-size: 10px;">SE</a> <a href="/tags/SPGAN/" style="font-size: 10px;">SPGAN</a> <a href="/tags/VOS/" style="font-size: 10px;">VOS</a> <a href="/tags/a/" style="font-size: 10px;">a</a> <a href="/tags/attention/" style="font-size: 13.33px;">attention</a> <a href="/tags/b/" style="font-size: 10px;">b</a> <a href="/tags/cross-domain/" style="font-size: 10px;">cross domain</a> <a href="/tags/cross-domain-person-re-id/" style="font-size: 10px;">cross-domain person re-id</a> <a href="/tags/cuda/" style="font-size: 11.67px;">cuda</a> <a href="/tags/cudnn/" style="font-size: 10px;">cudnn</a> <a href="/tags/cycleGAN/" style="font-size: 10px;">cycleGAN</a> <a href="/tags/data/" style="font-size: 10px;">data</a> <a href="/tags/data-VOS/" style="font-size: 10px;">data_VOS</a> <a href="/tags/deep-learning/" style="font-size: 10px;">deep-learning</a> <a href="/tags/docker/" style="font-size: 11.67px;">docker</a> <a href="/tags/domain-adaption/" style="font-size: 10px;">domain adaption</a> <a href="/tags/domain-guided-distillation/" style="font-size: 10px;">domain guided distillation</a> <a href="/tags/driver/" style="font-size: 10px;">driver</a> <a href="/tags/face-recognition/" style="font-size: 10px;">face recognition</a> <a href="/tags/face-synthesis/" style="font-size: 10px;">face synthesis</a> <a href="/tags/few-shot/" style="font-size: 10px;">few-shot</a> <a href="/tags/few-shot-learning/" style="font-size: 10px;">few-shot learning</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/github/" style="font-size: 11.67px;">github</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/html/" style="font-size: 10px;">html</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/markdown/" style="font-size: 11.67px;">markdown</a> <a href="/tags/mask-and-colour/" style="font-size: 10px;">mask and colour</a> <a href="/tags/math/" style="font-size: 10px;">math</a> <a href="/tags/mathjax/" style="font-size: 10px;">mathjax</a> <a href="/tags/memory/" style="font-size: 11.67px;">memory</a> <a href="/tags/meta-learning/" style="font-size: 10px;">meta-learning</a> <a href="/tags/multi-domain/" style="font-size: 10px;">multi-domain</a> <a href="/tags/network/" style="font-size: 10px;">network</a> <a href="/tags/neural-style-transfer/" style="font-size: 10px;">neural style transfer</a> <a href="/tags/npm/" style="font-size: 10px;">npm</a> <a href="/tags/numpy/" style="font-size: 11.67px;">numpy</a> <a href="/tags/object-detection/" style="font-size: 10px;">object detection</a> <a href="/tags/one-example/" style="font-size: 10px;">one_example</a> <a href="/tags/paper/" style="font-size: 15px;">paper</a> <a href="/tags/person-re-id/" style="font-size: 18.33px;">person re-id</a> <a href="/tags/person-re-identification/" style="font-size: 10px;">person re-identification</a> <a href="/tags/person-reid/" style="font-size: 11.67px;">person-reid</a> <a href="/tags/python/" style="font-size: 13.33px;">python</a> <a href="/tags/python-picture/" style="font-size: 10px;">python,picture</a> <a href="/tags/pytorch/" style="font-size: 16.67px;">pytorch</a> <a href="/tags/pytorch-learn-chenyun/" style="font-size: 10px;">pytorch-learn chenyun</a> <a href="/tags/re-ID/" style="font-size: 10px;">re-ID</a> <a href="/tags/re-id/" style="font-size: 11.67px;">re-id</a> <a href="/tags/segmentation/" style="font-size: 10px;">segmentation</a> <a href="/tags/semantice-segmentation/" style="font-size: 10px;">semantice segmentation</a> <a href="/tags/sharelatex/" style="font-size: 10px;">sharelatex</a> <a href="/tags/softmax/" style="font-size: 10px;">softmax</a> <a href="/tags/starGAN/" style="font-size: 10px;">starGAN</a> <a href="/tags/tensorboard/" style="font-size: 10px;">tensorboard</a> <a href="/tags/tensorflow/" style="font-size: 13.33px;">tensorflow</a> <a href="/tags/transfer-learning/" style="font-size: 10px;">transfer learning</a> <a href="/tags/%E5%8D%B7%E7%A7%AF-%E5%8F%8D%E5%8D%B7%E7%A7%AF-%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF/" style="font-size: 10px;">卷积\反卷积 空洞卷积</a> <a href="/tags/%E5%9F%BA%E7%A1%80/" style="font-size: 10px;">基础</a> <a href="/tags/%E5%AE%B9%E5%99%A8/" style="font-size: 10px;">容器</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">计算机操作系统</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/11/">November 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/11/06/test-2011-11-06/">test_2011_11_06</a>
          </li>
        
          <li>
            <a href="/2020/09/23/python-100-days/">python_100_days</a>
          </li>
        
          <li>
            <a href="/2020/09/22/data-VOS/">data_VOS</a>
          </li>
        
          <li>
            <a href="/2020/09/22/TVOS/">TVOS</a>
          </li>
        
          <li>
            <a href="/2020/09/22/computer_system/">计算机组成原理</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>