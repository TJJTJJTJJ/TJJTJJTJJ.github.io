<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="GAN,mask and colour," />










<meta name="description" content="0. 前言这篇文章是根据GANnotation的一个公式查过来的，感觉还挺厉害。 \hat{I}&#x3D;(1-M) \circ C + M \circ I paper: GANimation Anatomically-aware Facial Animation from a Single Image github: https:&#x2F;&#x2F;github.com&#x2F;albertpumarola&#x2F;GANimatio">
<meta property="og:type" content="article">
<meta property="og:title" content="GANimation">
<meta property="og:url" content="http://example.com/2019/01/24/GANimation/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="0. 前言这篇文章是根据GANnotation的一个公式查过来的，感觉还挺厉害。 \hat{I}&#x3D;(1-M) \circ C + M \circ I paper: GANimation Anatomically-aware Facial Animation from a Single Image github: https:&#x2F;&#x2F;github.com&#x2F;albertpumarola&#x2F;GANimatio">
<meta property="og:locale">
<meta property="og:image" content="http://example.com/2019/01/24/GANimation/GANimation/GANimation1.png">
<meta property="og:image" content="http://example.com/2019/01/24/GANimation/GANimation/GANimation2.png">
<meta property="og:image" content="http://example.com/2019/01/24/GANimation/GANimation/GANimation3.png">
<meta property="og:image" content="http://example.com/2019/01/24/GANimation/GANimation/GANimation4.png">
<meta property="og:image" content="http://example.com/2019/01/24/GANimation/GANimation/GANimation5.png">
<meta property="og:image" content="http://example.com/2019/01/24/GANimation/GANimation/GANimation6.png">
<meta property="og:image" content="http://example.com/2019/01/24/GANimation/GANimation/GANimation7.png">
<meta property="og:image" content="http://example.com/2019/01/24/GANimation/GANimation/GANimation8.png">
<meta property="article:published_time" content="2019-01-24T07:53:06.000Z">
<meta property="article:modified_time" content="2019-03-28T08:15:53.709Z">
<meta property="article:author" content="TianJiajie">
<meta property="article:tag" content="GAN">
<meta property="article:tag" content="mask and colour">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2019/01/24/GANimation/GANimation/GANimation1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://example.com/2019/01/24/GANimation/"/>





  <title>GANimation | Hexo</title>
  








<meta name="generator" content="Hexo 6.3.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-something">
          <a href="/something" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            something
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/01/24/GANimation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">GANimation</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-24T15:53:06+08:00">
                2019-01-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GAN/" itemprop="url" rel="index">
                    <span itemprop="name">GAN</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="0-前言"><a href="#0-前言" class="headerlink" title="0. 前言"></a>0. 前言</h1><p>这篇文章是根据GANnotation的一个公式查过来的，感觉还挺厉害。</p>
<script type="math/tex; mode=display">\hat{I}=(1-M) \circ C + M \circ I</script><ul>
<li>paper: <a target="_blank" rel="noopener" href="https://www.albertpumarola.com/publications/files/pumarola2018ganimation.pdf">GANimation Anatomically-aware Facial Animation from a Single Image</a></li>
<li>github: <a target="_blank" rel="noopener" href="https://github.com/albertpumarola/GANimation">https://github.com/albertpumarola/GANimation</a></li>
<li>project: <a target="_blank" rel="noopener" href="https://www.albertpumarola.com/research/GANimation/index.html">https://www.albertpumarola.com/research/GANimation/index.html</a></li>
</ul>
<p>关键词：starGAN的改进、连续的表情变换、贴回去能够一致</p>
<span id="more"></span>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>在人脸转换中，StarGAN是最成功的GAN，但是只能生成离散的人脸。作者要做的就是生成连续的表情变化。</p>
<h1 id="2-Problem-Formulation"><a href="#2-Problem-Formulation" class="headerlink" title="2. Problem Formulation"></a>2. Problem Formulation</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">符号</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$\mathrm{I}_{y_r}\in \mathbb{R}^{H×W×3}$</td>
<td style="text-align:center">输入图片</td>
</tr>
<tr>
<td style="text-align:center">$\mathrm{y}_r=(y_1,…,y_N)^T$</td>
<td style="text-align:center">其中，每一个$y_i$表示第i个action unit的程度，在0~1之间</td>
</tr>
<tr>
<td style="text-align:center">$\mathrm{I}_{y_g}$</td>
<td style="text-align:center">输出图片</td>
</tr>
<tr>
<td style="text-align:center">$\mathcal{M}$</td>
<td style="text-align:center">映射函数M: $(\mathrm{I}<em>{y_r},\mathrm{y}_g)$—&gt;$\mathrm{I}</em>{y_g}$</td>
</tr>
</tbody>
</table>
</div>
<p>非成对图片</p>
<h1 id="3-Our-Approach"><a href="#3-Our-Approach" class="headerlink" title="3. Our Approach"></a>3. Our Approach</h1><p><img src="./GANimation/GANimation1.png" alt="网络结构"><br></p>
<h2 id="3-1-Network-Architechture"><a href="#3-1-Network-Architechture" class="headerlink" title="3.1 Network Architechture"></a>3.1 Network Architechture</h2><h3 id="3-1-1-Generator"><a href="#3-1-1-Generator" class="headerlink" title="3.1.1 Generator"></a>3.1.1 Generator</h3><p>对于G的改进，为了能够使G只聚焦于对于新表情的生成，而保留其他元素，引入attention机制，也就是G生成的不是一整张图片，而是两个mask，color mask C 和 attention mask A.即：</p>
<script type="math/tex; mode=display">\mathrm{I}_{\mathrm{y}_f}=(1-A)\cdot C + A\cdot \mathrm{I}_{\mathrm{y}_o}</script><p>其中，$\mathrm{A}=G<em>A(\mathrm{I}</em>{\mathrm{y}<em>o}|\mathrm{y}_f)\in \{0,…,1\}^{H×W}$，$\mathrm{C}=G_C(\mathrm{I}</em>{\mathrm{y}_o}|\mathrm{y}_f)\in \{0,…,1\}^{H×W×3}$</p>
<p><img src="./GANimation/GANimation2.png" alt="生成器结构"><br></p>
<h3 id="3-1-2-Conditional-Critic"><a href="#3-1-2-Conditional-Critic" class="headerlink" title="3.1.2 Conditional Critic"></a>3.1.2 Conditional Critic</h3><p>PatchGAN: 输入图像 $\mathrm{I}\dashrightarrow \mathrm{Y}_{\mathrm{I}}\in \mathbb{R}^{H/2^6×W/2^6}$</p>
<p>并且对判别器进行改进，加入额外的回归判别类别。</p>
<h2 id="3-2-Learning-the-model"><a href="#3-2-Learning-the-model" class="headerlink" title="3.2 Learning the model"></a>3.2 Learning the model</h2><p>损失函数</p>
<h3 id="3-2-1-Image-Adversarial-Loss"><a href="#3-2-1-Image-Adversarial-Loss" class="headerlink" title="3.2.1 Image Adversarial Loss"></a>3.2.1 Image Adversarial Loss</h3><p>判断图片是生成的还是真实的。</p>
<p>和StarGAN的损失一样。</p>
<script type="math/tex; mode=display">L_I(G,D_I,I_{y_o},y_f)=\mathbb{E}_{\mathrm{I}_{\mathrm{y}_o}\thicksim \mathbb{P}_o}[D_\mathrm{I}(G(\mathrm{I}_{\mathrm{y}_o}|\mathrm{y}_f))]-\mathbb{E}_{\mathrm{I}_{\mathrm{y}_o}\thicksim \mathbb{P}_o}[D_\mathrm{I}(\mathrm{I}_{\mathrm{y}_o})]+\lambda_{gp} \mathbb{E}_{\tilde{I}\thicksim \mathbb{P}_{\tilde{I}}}[(\parallel \nabla_{\tilde{I}}D_I(\tilde{I}) \parallel _2-1)^2]</script><h3 id="3-2-2-Attention-Loss"><a href="#3-2-2-Attention-Loss" class="headerlink" title="3.2.2 Attention Loss"></a>3.2.2 Attention Loss</h3><p>这个损失是针对attention mask A 和 color mask C.</p>
<p>Total Variation Regularization</p>
<script type="math/tex; mode=display">L_A(G,I_{y_o},y_f)=\lambda_{TV}\mathbb{E}_{\mathrm{I}_{\mathrm{y}_o}\thicksim \mathbb{P}_o}[\sum_{i,j}^{H,W}[(A_{i+1,j}-A_{i,j})^2+(A_{i,j+1}-A_{i,j})^2]]+\mathbb{E}_{\mathrm{I}_{\mathrm{y}_o}\thicksim \mathbb{P}_o}[\parallel A \parallel_2]</script><p>这个公式的初步感觉是A要尽可能平缓，并且A中的元素尽可能小。</p>
<p>根据作者的说法，是为了保证A不变成全是1的矩阵，并且为了保证更加平滑的空间结合。以代码为准。</p>
<h3 id="3-2-3-Conditional-Expression-Loss"><a href="#3-2-3-Conditional-Expression-Loss" class="headerlink" title="3.2.3 Conditional Expression Loss"></a>3.2.3 Conditional Expression Loss</h3><p>这个应该和starGAN的判断图片属性分类正确损失是一样的。</p>
<script type="math/tex; mode=display">L_y(G,D_y,I_{y_o},y_o,y_f)=\mathbb{E}_{\mathrm{I}_{\mathrm{y}_o}\thicksim \mathbb{P}_o}[\parallel D_y(G(I_{y_o}|y_f))-y_f \parallel]+\mathbb{E}_{\mathrm{I}_{\mathrm{y}_o}\thicksim \mathbb{P}_o}[\parallel D_y(I_{y_o})-y_o \parallel]</script><h3 id="3-2-4-Identity-Loss"><a href="#3-2-4-Identity-Loss" class="headerlink" title="3.2.4 Identity Loss"></a>3.2.4 Identity Loss</h3><p>这个应该就是starGAN的重构损失</p>
<script type="math/tex; mode=display">L_{idg}(G,I_{y_o},y_o,y_f)=\mathbb{E}_{\mathrm{I}_{\mathrm{y}_o}\thicksim \mathbb{P}_o}[\parallel G(G(I_{y_o}|y_f)|y_o)-I_{y_o} \parallel _1]</script><p>这个损失是为了保证生成前后图片的id是一样的。</p>
<h3 id="3-2-5-Full-Loss"><a href="#3-2-5-Full-Loss" class="headerlink" title="3.2.5 Full Loss"></a>3.2.5 Full Loss</h3><script type="math/tex; mode=display">L=L_I+\lambda_y L_y+\lambda_A (L_A(G,I_{y_g},y_r)+L_A(G,I_{y_r},y_g))+\lambda_{idt}L_{idt}</script><script type="math/tex; mode=display">\lambda_{gp}=10, \lambda_A=0.1, \lambda_{TV}=0.0001, \lambda_y=4000, \lambda_{idt}=10</script><h1 id="4-Implementation-Details"><a href="#4-Implementation-Details" class="headerlink" title="4. Implementation Details"></a>4. Implementation Details</h1><p><strong>The attention mechanism guaranties a smooth transition between the morphed cropped face and the original image.</strong></p>
<p>也就是说 attention mechanism 能够保证生成的图片很好地再贴回去。</p>
<h2 id="4-1-Single-Action-Units-Edition"><a href="#4-1-Single-Action-Units-Edition" class="headerlink" title="4.1 Single Action Units Edition"></a>4.1 Single Action Units Edition</h2><p><img src="./GANimation/GANimation3.png" alt="Single Action Units Edition"><br></p>
<ul>
<li>[x] 这里的AU是什么？ intensity怎么理解？</li>
</ul>
<p>AU:<a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~face/facs.htm">https://www.cs.cmu.edu/~face/facs.htm</a></p>
<p>intensity: <a target="_blank" rel="noopener" href="https://github.com/TadasBaltrusaitis/OpenFace/wiki/Action-Units">https://github.com/TadasBaltrusaitis/OpenFace/wiki/Action-Units</a></p>
<p><img src="./GANimation/GANimation4.png" alt="Attention Model"><br></p>
<h2 id="4-2-Simultaneous-Edition-of-Multiple-AUs"><a href="#4-2-Simultaneous-Edition-of-Multiple-AUs" class="headerlink" title="4.2 Simultaneous Edition of Multiple AUs"></a>4.2 Simultaneous Edition of Multiple AUs</h2><p><img src="./GANimation/GANimation5.png" alt="Facial animation from a single image"><br></p>
<script type="math/tex; mode=display">\alpha y_g+(1-\alpha)y_r</script><h2 id="4-3-Discrete-Emotions-Editing"><a href="#4-3-Discrete-Emotions-Editing" class="headerlink" title="4.3 Discrete Emotions Editing"></a>4.3 Discrete Emotions Editing</h2><p><img src="./GANimation/GANimation6.png" alt="Qualitative comparison"><br></p>
<p>作者生成的图片比StarGAN更清晰。</p>
<h2 id="4-4-High-Expressions-Variability"><a href="#4-4-High-Expressions-Variability" class="headerlink" title="4.4 High Expressions Variability"></a>4.4 High Expressions Variability</h2><h2 id="4-5-Images-in-the-Wild"><a href="#4-5-Images-in-the-Wild" class="headerlink" title="4.5 Images in the Wild"></a>4.5 Images in the Wild</h2><p><img src="./GANimation/GANimation7.png" alt="Qualitative evaluation on images in the wild"><br></p>
<p>作者先检测到人脸，然后扣下来，做训练测试，然后再贴回去，与原图保持了一样的清晰度，个人猜测是因为表情的变化只在人脸的中央就可以完成，不涉及到背景的变换，如果涉及到背景的变换，那么是否还能保证贴回去与原图保持一致性。</p>
<h2 id="4-6-Pushing-the-Limits-of-the-Model"><a href="#4-6-Pushing-the-Limits-of-the-Model" class="headerlink" title="4.6 Pushing the Limits of the Model"></a>4.6 Pushing the Limits of the Model</h2><p><img src="./GANimation/GANimation8.png" alt="Success and Failure Cases"><br></p>
<h1 id="5-code"><a href="#5-code" class="headerlink" title="5. code"></a>5. code</h1><h2 id="5-1-生成器Generator"><a href="#5-1-生成器Generator" class="headerlink" title="5.1 生成器Generator"></a>5.1 生成器Generator</h2><p>GANimation的Generator的主体网络和starGAN的Generator的主体网络一致，只是多加了一个conv</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(<span class="title class_ inherited__">NetworkBase</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Generator. Encoder-Decoder Architecture.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, conv_dim=<span class="number">64</span>, c_dim=<span class="number">5</span>, repeat_num=<span class="number">6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self._name = <span class="string">&#x27;generator_wgan&#x27;</span></span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(nn.Conv2d(<span class="number">3</span>+c_dim, conv_dim, kernel_size=<span class="number">7</span>, stride=<span class="number">1</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>))</span><br><span class="line">        layers.append(nn.InstanceNorm2d(conv_dim, affine=<span class="literal">True</span>))</span><br><span class="line">        layers.append(nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Down-Sampling</span></span><br><span class="line">        curr_dim = conv_dim</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            layers.append(nn.Conv2d(curr_dim, curr_dim*<span class="number">2</span>, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>))</span><br><span class="line">            layers.append(nn.InstanceNorm2d(curr_dim*<span class="number">2</span>, affine=<span class="literal">True</span>))</span><br><span class="line">            layers.append(nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line">            curr_dim = curr_dim * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Bottleneck</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(repeat_num):</span><br><span class="line">            layers.append(ResidualBlock(dim_in=curr_dim, dim_out=curr_dim))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Up-Sampling</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            layers.append(nn.ConvTranspose2d(curr_dim, curr_dim//<span class="number">2</span>, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>))</span><br><span class="line">            layers.append(nn.InstanceNorm2d(curr_dim//<span class="number">2</span>, affine=<span class="literal">True</span>))</span><br><span class="line">            layers.append(nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line">            curr_dim = curr_dim // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        self.main = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(nn.Conv2d(curr_dim, <span class="number">3</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">1</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>))</span><br><span class="line">        layers.append(nn.Tanh())</span><br><span class="line">        self.img_reg = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(nn.Conv2d(curr_dim, <span class="number">1</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">1</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>))</span><br><span class="line">        layers.append(nn.Sigmoid())</span><br><span class="line">        self.attetion_reg = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, c</span>):</span><br><span class="line">        <span class="comment"># replicate spatially and concatenate domain information</span></span><br><span class="line">        c = c.unsqueeze(<span class="number">2</span>).unsqueeze(<span class="number">3</span>)</span><br><span class="line">        c = c.expand(c.size(<span class="number">0</span>), c.size(<span class="number">1</span>), x.size(<span class="number">2</span>), x.size(<span class="number">3</span>))</span><br><span class="line">        x = torch.cat([x, c], dim=<span class="number">1</span>)</span><br><span class="line">        features = self.main(x)</span><br><span class="line">        <span class="keyword">return</span> self.img_reg(features), self.attetion_reg(features)</span><br></pre></td></tr></table></figure>
<h2 id="5-2-Discriminator"><a href="#5-2-Discriminator" class="headerlink" title="5.2 Discriminator"></a>5.2 Discriminator</h2><p>Discriminator和StarGAN 的Discriminator完全一样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(<span class="title class_ inherited__">NetworkBase</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Discriminator. PatchGAN.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_size=<span class="number">128</span>, conv_dim=<span class="number">64</span>, c_dim=<span class="number">5</span>, repeat_num=<span class="number">6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self._name = <span class="string">&#x27;discriminator_wgan&#x27;</span></span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(nn.Conv2d(<span class="number">3</span>, conv_dim, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line">        layers.append(nn.LeakyReLU(<span class="number">0.01</span>, inplace=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">        curr_dim = conv_dim</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, repeat_num):</span><br><span class="line">            layers.append(nn.Conv2d(curr_dim, curr_dim*<span class="number">2</span>, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line">            layers.append(nn.LeakyReLU(<span class="number">0.01</span>, inplace=<span class="literal">True</span>))</span><br><span class="line">            curr_dim = curr_dim * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        k_size = <span class="built_in">int</span>(image_size / np.power(<span class="number">2</span>, repeat_num))</span><br><span class="line">        self.main = nn.Sequential(*layers)</span><br><span class="line">        self.conv1 = nn.Conv2d(curr_dim, <span class="number">1</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(curr_dim, c_dim, kernel_size=k_size, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        h = self.main(x)</span><br><span class="line">        out_real = self.conv1(h)</span><br><span class="line">        out_aux = self.conv2(h)</span><br><span class="line">        <span class="keyword">return</span> out_real.squeeze(), out_aux.squeeze()</span><br></pre></td></tr></table></figure>
<h2 id="5-3-train-D"><a href="#5-3-train-D" class="headerlink" title="5.3 train D"></a>5.3 train D</h2><p>这里训练D的过程和starGAN有所不同，并且超参数也有所不同。</p>
<script type="math/tex; mode=display">\lambda_{D-cond}=4000, \lambda_{gp}=10</script><p>starGAN:</p>
<script type="math/tex; mode=display">\lambda_{cls}=1, \lambda_{gp}=10</script><ul>
<li>[ ] 为什么和怎么使用的MSELoss</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># starGAN是把Image Adversarial Loss的三项一起反向传播，但GANimation是分开反向传播的，不确定这么做是否有影响。</span></span><br><span class="line">loss_D, fake_imgs_masked = self._forward_D()</span><br><span class="line">self._optimizer_D.zero_grad()</span><br><span class="line">loss_D.backward()</span><br><span class="line">self._optimizer_D.step()</span><br><span class="line"></span><br><span class="line">loss_D_gp= self._gradinet_penalty_D(fake_imgs_masked)</span><br><span class="line">self._optimizer_D.zero_grad()</span><br><span class="line">loss_D_gp.backward()</span><br><span class="line">self._optimizer_D.step()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_forward_D</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># generate fake images</span></span><br><span class="line">    fake_imgs, fake_img_mask = self._G.forward(self._real_img, self._desired_cond)</span><br><span class="line">    fake_img_mask = self._do_if_necessary_saturate_mask(fake_img_mask, saturate=self._opt.do_saturate_mask)</span><br><span class="line">    fake_imgs_masked = fake_img_mask * self._real_img + (<span class="number">1</span> - fake_img_mask) * fake_imgs</span><br><span class="line"></span><br><span class="line">    <span class="comment"># D(real_I)</span></span><br><span class="line">    <span class="comment"># 识别真图片为真，(Image Adversarial Loss)</span></span><br><span class="line">    <span class="comment"># 图片类别分类准确，这里的分类用的不是交叉熵，而是MSELoss，(Conditional Expression Loss)</span></span><br><span class="line">    <span class="comment"># 刚刚发现一个问题，如果是分类损失，MSELoss的输入必须是同样大小的，按照starGAN，D的输出是类别大小(batch*classification)，G的输入是(batch*1)，那这个样子肯定是没法进行MSELoss的，所以还需要看了数据的处理之后才能明白怎么回事。</span></span><br><span class="line">    <span class="comment"># self._criterion_D_cond = torch.nn.MSELoss().cuda()</span></span><br><span class="line">    d_real_img_prob, d_real_img_cond = self._D.forward(self._real_img)</span><br><span class="line">    self._loss_d_real = self._compute_loss_D(d_real_img_prob, <span class="literal">True</span>) * self._opt.lambda_D_prob</span><br><span class="line">    self._loss_d_cond = self._criterion_D_cond(d_real_img_cond, self._real_cond) / self._B * self._opt.lambda_D_cond</span><br><span class="line"></span><br><span class="line">    <span class="comment"># D(fake_I)</span></span><br><span class="line">    <span class="comment"># 识别假图片为假，(Image Adversarial Loss)</span></span><br><span class="line">    d_fake_desired_img_prob, _ = self._D.forward(fake_imgs_masked.detach())</span><br><span class="line">    self._loss_d_fake = self._compute_loss_D(d_fake_desired_img_prob, <span class="literal">False</span>) * self._opt.lambda_D_prob</span><br><span class="line"></span><br><span class="line">    <span class="comment"># combine losses</span></span><br><span class="line">    <span class="keyword">return</span> self._loss_d_real + self._loss_d_cond + self._loss_d_fake, fake_imgs_masked</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_compute_loss_D</span>(<span class="params">self, estim, is_real</span>):</span><br><span class="line">    <span class="keyword">return</span> -torch.mean(estim) <span class="keyword">if</span> is_real <span class="keyword">else</span> torch.mean(estim)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_gradinet_penalty_D</span>(<span class="params">self, fake_imgs_masked</span>):</span><br><span class="line">    <span class="comment"># (Image Adversarial Loss)的第三项</span></span><br><span class="line">    <span class="comment"># interpolate sample</span></span><br><span class="line">    alpha = torch.rand(self._B, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).cuda().expand_as(self._real_img)</span><br><span class="line">    interpolated = Variable(alpha * self._real_img.data + (<span class="number">1</span> - alpha) * fake_imgs_masked.data, requires_grad=<span class="literal">True</span>)</span><br><span class="line">    interpolated_prob, _ = self._D(interpolated)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute gradients</span></span><br><span class="line">    grad = torch.autograd.grad(outputs=interpolated_prob,</span><br><span class="line">                                inputs=interpolated,</span><br><span class="line">                                grad_outputs=torch.ones(interpolated_prob.size()).cuda(),</span><br><span class="line">                                retain_graph=<span class="literal">True</span>,</span><br><span class="line">                                create_graph=<span class="literal">True</span>,</span><br><span class="line">                                only_inputs=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># penalize gradients</span></span><br><span class="line">    grad = grad.view(grad.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    grad_l2norm = torch.sqrt(torch.<span class="built_in">sum</span>(grad ** <span class="number">2</span>, dim=<span class="number">1</span>))</span><br><span class="line">    self._loss_d_gp = torch.mean((grad_l2norm - <span class="number">1</span>) ** <span class="number">2</span>) * self._opt.lambda_D_gp</span><br></pre></td></tr></table></figure>
<h2 id="5-4-train-G"><a href="#5-4-train-G" class="headerlink" title="5.4 train G"></a>5.4 train G</h2><p>这一部分和starGAN的训练类似，比starGAN多一个mask的平滑loss。</p>
<script type="math/tex; mode=display">\lambda_{D-cond}=4000, \lambda_{cyc}=10, \lambda_{mask}=0.1, \lambda_{mask-smooth}=1*e^{-5}</script><p>starGAN:</p>
<script type="math/tex; mode=display">\lambda_{cls}=1, \lambda_{cyc}=10</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_forward_G</span>(<span class="params">self, keep_data_for_visuals</span>):</span><br><span class="line">    <span class="comment"># generate fake images</span></span><br><span class="line">    fake_imgs, fake_img_mask = self._G.forward(self._real_img, self._desired_cond)</span><br><span class="line">    fake_img_mask = self._do_if_necessary_saturate_mask(fake_img_mask, saturate=self._opt.do_saturate_mask)</span><br><span class="line">    fake_imgs_masked = fake_img_mask * self._real_img + (<span class="number">1</span> - fake_img_mask) * fake_imgs</span><br><span class="line"></span><br><span class="line">    <span class="comment"># D(G(Ic1, c2)*M) masked</span></span><br><span class="line">    <span class="comment"># 生成图片为真 (Image Adversarial Loss)</span></span><br><span class="line">    <span class="comment"># 生成图片的属性为真 (Conditional Expression Loss)</span></span><br><span class="line">    d_fake_desired_img_masked_prob, d_fake_desired_img_masked_cond = self._D.forward(fake_imgs_masked)</span><br><span class="line">    self._loss_g_masked_fake = self._compute_loss_D(d_fake_desired_img_masked_prob, <span class="literal">True</span>) * self._opt.lambda_D_prob</span><br><span class="line">    self._loss_g_masked_cond = self._criterion_D_cond(d_fake_desired_img_masked_cond, self._desired_cond) / self._B * self._opt.lambda_D_cond</span><br><span class="line"></span><br><span class="line">    <span class="comment"># G(G(Ic1,c2), c1)</span></span><br><span class="line">    <span class="comment"># 重构损失 (Identity Loss)</span></span><br><span class="line">    rec_real_img_rgb, rec_real_img_mask = self._G.forward(fake_imgs_masked, self._real_cond)</span><br><span class="line">    rec_real_img_mask = self._do_if_necessary_saturate_mask(rec_real_img_mask, saturate=self._opt.do_saturate_mask)</span><br><span class="line">    rec_real_imgs = rec_real_img_mask * fake_imgs_masked + (<span class="number">1</span> - rec_real_img_mask) * rec_real_img_rgb</span><br><span class="line"></span><br><span class="line">    <span class="comment"># l_cyc(G(G(Ic1,c2), c1)*M)</span></span><br><span class="line">    self._loss_g_cyc = self._criterion_cycle(rec_real_imgs, self._real_img) * self._opt.lambda_cyc</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loss mask</span></span><br><span class="line">    <span class="comment"># (Attention Loss) 不仅对生成的mask进行了平滑，也对重构生成的mask进行了平滑损失</span></span><br><span class="line">    self._loss_g_mask_1 = torch.mean(fake_img_mask) * self._opt.lambda_mask</span><br><span class="line">    self._loss_g_mask_2 = torch.mean(rec_real_img_mask) * self._opt.lambda_mask</span><br><span class="line">    self._loss_g_mask_1_smooth = self._compute_loss_smooth(fake_img_mask) * self._opt.lambda_mask_smooth</span><br><span class="line">    self._loss_g_mask_2_smooth = self._compute_loss_smooth(rec_real_img_mask) * self._opt.lambda_mask_smooth</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_compute_loss_smooth</span>(<span class="params">self, mat</span>):</span><br><span class="line">    <span class="keyword">return</span> torch.<span class="built_in">sum</span>(torch.<span class="built_in">abs</span>(mat[:, :, :, :-<span class="number">1</span>] - mat[:, :, :, <span class="number">1</span>:])) + \</span><br><span class="line">            torch.<span class="built_in">sum</span>(torch.<span class="built_in">abs</span>(mat[:, :, :-<span class="number">1</span>, :] - mat[:, :, <span class="number">1</span>:, :]))</span><br></pre></td></tr></table></figure>
<h2 id="5-5-保存图片"><a href="#5-5-保存图片" class="headerlink" title="5.5 保存图片"></a>5.5 保存图片</h2><p>这个保存图片在starGAN就没有太理解，在这里又看到了类似的，才理解这是对输入图片归一化的反向操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># starGAN</span></span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">denorm</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert the range from [-1, 1] to [0, 1].&quot;&quot;&quot;</span></span><br><span class="line">    out = (x + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> out.clamp_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">save_image(self.denorm(x_concat.data.cpu()), sample_path, nrow=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># GANimation</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">mean = [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]</span><br><span class="line">std = [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]</span><br><span class="line"><span class="keyword">for</span> i, m, s <span class="keyword">in</span> <span class="built_in">zip</span>(img, mean, std):</span><br><span class="line">  i.mul_(s).add_(m)</span><br><span class="line">image_numpy = img.numpy()</span><br><span class="line">image_numpy_t = np.transpose(image_numpy, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">image_numpy_t = image_numpy_t*<span class="number">254.0</span></span><br><span class="line">image_numpy_t.astype(np.uint8)</span><br></pre></td></tr></table></figure>
<h2 id="5-6-其他"><a href="#5-6-其他" class="headerlink" title="5.6 其他"></a>5.6 其他</h2><p>没有实际跑这个代码，所以对于一些细节不是很清晰，尤其是数据处理那里，暂时根据查到的AU资料理解成17个AU(但1, 2, 4, 5, 6, 7, 9, 10, 12, 14, 15, 17, 20, 23, 25, 26, 28, and 45是18个AU)，每个AU是一个0~5的数字。</p>
<p>但是对于作者所说的能够生成连续的表情变换，这一点只能在测试代码中看出，但是在训练的时候并没有特意去表示连续的变化，暂时对于连续的变化存疑。</p>
<p>主要是openface这个库有点晕，等数据集下载之后试试。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/albertpumarola/GANimation/issues/45">https://github.com/albertpumarola/GANimation/issues/45</a><br><a target="_blank" rel="noopener" href="https://github.com/albertpumarola/GANimation/issues/62">https://github.com/albertpumarola/GANimation/issues/62</a><br><a target="_blank" rel="noopener" href="https://github.com/albertpumarola/GANimation/issues/43">https://github.com/albertpumarola/GANimation/issues/43</a><br><a target="_blank" rel="noopener" href="https://github.com/albertpumarola/GANimation/issues/32">https://github.com/albertpumarola/GANimation/issues/32</a><br><a target="_blank" rel="noopener" href="https://github.com/albertpumarola/GANimation/issues/25">https://github.com/albertpumarola/GANimation/issues/25</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/GAN/" rel="tag"># GAN</a>
          
            <a href="/tags/mask-and-colour/" rel="tag"># mask and colour</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/01/17/GANnotation/" rel="next" title="GANnotation">
                <i class="fa fa-chevron-left"></i> GANnotation
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/27/One-Example-reID/" rel="prev" title="One_Example_reID">
                One_Example_reID <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">76</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">44</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">73</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#0-%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">0. 前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Introduction"><span class="nav-number">2.</span> <span class="nav-text">1. Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Problem-Formulation"><span class="nav-number">3.</span> <span class="nav-text">2. Problem Formulation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Our-Approach"><span class="nav-number">4.</span> <span class="nav-text">3. Our Approach</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Network-Architechture"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 Network Architechture</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-1-Generator"><span class="nav-number">4.1.1.</span> <span class="nav-text">3.1.1 Generator</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-2-Conditional-Critic"><span class="nav-number">4.1.2.</span> <span class="nav-text">3.1.2 Conditional Critic</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-Learning-the-model"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 Learning the model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-1-Image-Adversarial-Loss"><span class="nav-number">4.2.1.</span> <span class="nav-text">3.2.1 Image Adversarial Loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-2-Attention-Loss"><span class="nav-number">4.2.2.</span> <span class="nav-text">3.2.2 Attention Loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-3-Conditional-Expression-Loss"><span class="nav-number">4.2.3.</span> <span class="nav-text">3.2.3 Conditional Expression Loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-4-Identity-Loss"><span class="nav-number">4.2.4.</span> <span class="nav-text">3.2.4 Identity Loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-5-Full-Loss"><span class="nav-number">4.2.5.</span> <span class="nav-text">3.2.5 Full Loss</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Implementation-Details"><span class="nav-number">5.</span> <span class="nav-text">4. Implementation Details</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-Single-Action-Units-Edition"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 Single Action Units Edition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-Simultaneous-Edition-of-Multiple-AUs"><span class="nav-number">5.2.</span> <span class="nav-text">4.2 Simultaneous Edition of Multiple AUs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-Discrete-Emotions-Editing"><span class="nav-number">5.3.</span> <span class="nav-text">4.3 Discrete Emotions Editing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-4-High-Expressions-Variability"><span class="nav-number">5.4.</span> <span class="nav-text">4.4 High Expressions Variability</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-5-Images-in-the-Wild"><span class="nav-number">5.5.</span> <span class="nav-text">4.5 Images in the Wild</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-6-Pushing-the-Limits-of-the-Model"><span class="nav-number">5.6.</span> <span class="nav-text">4.6 Pushing the Limits of the Model</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-code"><span class="nav-number">6.</span> <span class="nav-text">5. code</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-%E7%94%9F%E6%88%90%E5%99%A8Generator"><span class="nav-number">6.1.</span> <span class="nav-text">5.1 生成器Generator</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-Discriminator"><span class="nav-number">6.2.</span> <span class="nav-text">5.2 Discriminator</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-train-D"><span class="nav-number">6.3.</span> <span class="nav-text">5.3 train D</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-4-train-G"><span class="nav-number">6.4.</span> <span class="nav-text">5.4 train G</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-5-%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87"><span class="nav-number">6.5.</span> <span class="nav-text">5.5 保存图片</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-6-%E5%85%B6%E4%BB%96"><span class="nav-number">6.6.</span> <span class="nav-text">5.6 其他</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">TianJiajie</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
